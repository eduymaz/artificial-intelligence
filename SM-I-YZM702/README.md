# DÄ°YABETÄ°K HASTALARIN 30 GÃœN Ä°Ã‡Ä°NDE HASTANEYE TEKRAR YATIÅ TAHMÄ°NÄ°

#### ğŸ‘©ğŸ¼â€ğŸ’»**Elif Duymaz YÄ±lmaz, 6067007**
##### **OCAK 2, 2026**
_**YZM702 - Makine Ã–ÄŸrenmesi Temelleri Final Raporu**_

## 1. GÄ°RÄ°Å VE PROBLEM TANIMI

### 1.1 Projenin Motivasyonu ve Ã–nemi

Diyabet, gÃ¼nÃ¼mÃ¼zde dÃ¼nya genelinde yaklaÅŸÄ±k 537 milyon yetiÅŸkini etkileyen ve kÃ¼resel saÄŸlÄ±k sistemleri Ã¼zerinde muazzam bir baskÄ± oluÅŸturan kronik bir metabolik hastalÄ±ktÄ±r. Hastanede tedavi gÃ¶ren diyabetik hastalarÄ±n taburcu edildikten sonraki ilk 30 gÃ¼n iÃ§inde tekrar hastaneye yatÄ±ÅŸ yapmasÄ±, hem hasta saÄŸlÄ±ÄŸÄ± hem de saÄŸlÄ±k sisteminin ekonomik sÃ¼rdÃ¼rÃ¼lebilirliÄŸi aÃ§Ä±sÄ±ndan en kritik problemlerden biri olarak kabul edilmektedir. Klinik aÃ§Ä±dan bu erken tekrar yatÄ±ÅŸlar; yetersiz taburculuk planlamasÄ±, hastanÄ±n tedaviye uyumsuzluÄŸu, hastalÄ±k yÃ¶netimindeki sistemik aksaklÄ±klar veya bakÄ±m hizmetleri arasÄ±ndaki koordinasyon eksikliÄŸi gibi temel sorunlara iÅŸaret etmektedir. Bu baÄŸlamda, **30 gÃ¼n iÃ§indeki tekrar yatÄ±ÅŸ oranlarÄ±,** sunulan saÄŸlÄ±k hizmetinin kalitesini Ã¶lÃ§en temel bir gÃ¶sterge niteliÄŸi taÅŸÄ±maktadÄ±r.

**Problemin Klinik Ã–nemi:**

Hastaneye tekrar yatÄ±ÅŸ, genellikle aÅŸaÄŸÄ±daki durumlarÄ± iÅŸaret etmektedir:
- Yetersiz veya eksik taburculuk planlamasÄ±
- Hasta tarafÄ±ndan tedaviye uyumsuzluk
- HastalÄ±k yÃ¶netimindeki sistemik sorunlar
- Koordine olmayan bakÄ±m hizmetleri

30 gÃ¼n iÃ§indeki erken tekrar yatÄ±ÅŸlar, Ã¶zellikle Ã¶nlenebilir durumlarÄ± gÃ¶stermesi nedeniyle saÄŸlÄ±k hizmeti kalitesinin bir gÃ¶stergesi olarak kabul edilmektedir.

**Problemin Ekonomik Boyutu:**

- Amerika BirleÅŸik Devletleri'nde Medicare gibi sigortacÄ±lar, bazÄ± durumlarda 30 gÃ¼nlÃ¼k tekrar yatÄ±ÅŸlarÄ± geri Ã¶dememektedir.
- Hastaneler iÃ§in finansal cezalar ve itibar kaybÄ±na neden olmaktadÄ±r.
- Ulusal dÃ¼zeyde yÄ±llÄ±k milyarlarca dolarlÄ±k ek maliyet oluÅŸturmaktadÄ±r.

**Makine Ã–ÄŸrenmesi ile Ã‡Ã¶zÃ¼m Potansiyeli:**

YÃ¼ksek riskli hastalarÄ±n makine Ã¶ÄŸrenmesi modelleri ile Ã¶nceden belirlenmesi, klinik ekiplerin:
- Hedefli mÃ¼dahaleler planlamasÄ±na
- Taburculuk sÃ¼reÃ§lerini optimize etmesine
- Hasta takibini gÃ¼Ã§lendirmesine
- KaynaklarÄ± daha etkin kullanmasÄ±na

olanak saÄŸlamaktadÄ±r.

### 1.2 Veri Seti TanÄ±tÄ±mÄ±

Bu projede kullanÄ±lan veri seti, **UCI Machine Learning Repository**'den temin edilen **["Diabetes 130-US Hospitals for Years 1999-2008"](https://archive.ics.uci.edu/dataset/296/diabetes+130-us+hospitals+for+years+1999-2008)** veri setidir.

**Veri Seti Ã–zellikleri:**

| Ã–zellik | DeÄŸer |
|---------|-------|
| **Kaynak** | UCI Machine Learning Repository |
| **Kapsam** | 130 ABD Hastanesi |
| **Zaman AralÄ±ÄŸÄ±** | 1999-2008 (10 yÄ±l) |
| **Toplam KayÄ±t** | 101,766 hasta kaydÄ± |
| **Ã–zellik SayÄ±sÄ±** | 50 deÄŸiÅŸken |
| **Veri Boyutu** | ~193 MB (bellek) |

*Hedef DeÄŸiÅŸken (readmitted):**

Veri setindeki hedef deÄŸiÅŸken `readmitted` Ã¼Ã§ kategori iÃ§ermektedir:
- `<30`: Hasta 30 gÃ¼nden Ã¶nce tekrar hastaneye yatÄ±rÄ±lmÄ±ÅŸ (Kritik durum)
- `>30`: Hasta 30 gÃ¼nden sonra tekrar hastaneye yatÄ±rÄ±lmÄ±ÅŸ
- `NO`: Hasta tekrar hastaneye yatÄ±rÄ±lmamÄ±ÅŸ

**Proje KapsamÄ±nda DÃ¶nÃ¼ÅŸÃ¼m:**

Bu proje kapsamÄ±nda problem, **binary (ikili) sÄ±nÄ±flandÄ±rma** problemi olarak ele alÄ±nmÄ±ÅŸtÄ±r:
- **SÄ±nÄ±f 1 (Pozitif):** `<30` - 30 gÃ¼n iÃ§inde tekrar yatÄ±ÅŸ (**yÃ¼ksek risk**)
- **SÄ±nÄ±f 0 (Negatif):** `>30` veya `NO` - DiÄŸer durumlar (**normal risk**)

Bu dÃ¶nÃ¼ÅŸÃ¼m, klinik aÃ§Ä±dan en kritik olan erken tekrar yatÄ±ÅŸlarÄ± tespit etmeye odaklanmaktadÄ±r.


**Veri Setinin KapsamÄ±:**

Veri seti aÅŸaÄŸÄ±daki bilgileri iÃ§ermektedir:
- **Demografik Bilgiler:** YaÅŸ, cinsiyet, Ä±rk
- **BaÅŸvuru Bilgileri:** Kabul tÃ¼rÃ¼, taburculuk durumu, sevk kaynaÄŸÄ±
- **Klinik Ã–lÃ§Ã¼mler:** Laboratuvar testleri sayÄ±sÄ±, prosedÃ¼r sayÄ±sÄ±, ilaÃ§ sayÄ±sÄ±
- **Hastanede KalÄ±ÅŸ:** YatÄ±ÅŸ sÃ¼resi (gÃ¼n)
- **TeÅŸhis KodlarÄ±:** Birincil, ikincil ve Ã¼Ã§Ã¼ncÃ¼l teÅŸhis kodlarÄ± (ICD-9)
- **Ä°laÃ§ Bilgileri:** 23 farklÄ± diyabet ilacÄ±nÄ±n kullanÄ±mÄ± ve doz deÄŸiÅŸiklikleri
- **Ã–nceki BaÅŸvurular:** Acil servis ziyaretleri, geÃ§miÅŸ hastaneye yatÄ±ÅŸlar

### 1.3 Projenin AmaÃ§larÄ± ve KapsamÄ±

Bu proje, **YZM702 - Makine Ã–ÄŸrenmesi Temelleri** dersi kapsamÄ±nda gerÃ§ekleÅŸtirilmiÅŸ olup, aÅŸaÄŸÄ±daki amaÃ§larÄ± hedeflemektedir:

**Temel AmaÃ§lar:**

1. **KapsamlÄ± Veri Analizi:** Diabetik hastane verilerinin detaylÄ± keÅŸfi ve istatistiksel analizinin yapÄ±lmasÄ±

2. **Veri Ã–n Ä°ÅŸleme:** Eksik deÄŸer yÃ¶netimi, aykÄ±rÄ± deÄŸer tespiti, kategorik kodlama ve Ã¶zellik mÃ¼hendisliÄŸi uygulamalarÄ±nÄ±n gerÃ§ekleÅŸtirilmesi

3. **Ã‡oklu Model KarÅŸÄ±laÅŸtÄ±rmasÄ±:** FarklÄ± makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ±n (Logistic Regression, Random Forest, SVM, XGBoost, LightGBM) performanslarÄ±nÄ±n karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±

4. **Model Optimizasyonu:** Hiperparametre ayarlama teknikleri ile en iyi model konfigÃ¼rasyonunun bulunmasÄ±

5. **Model YorumlanabilirliÄŸi:** Ã–zellik Ã¶nem analizi ile klinik iÃ§gÃ¶rÃ¼ler elde edilmesi

6. **Pratik Uygulanabilirlik:** GerÃ§ek dÃ¼nya saÄŸlÄ±k sistemlerinde kullanÄ±labilecek bir tahmin modeli geliÅŸtirilmesi

### 1.4 Projenin Beklenen DeÄŸeri

Bu projenin temel amacÄ±, diyabetik hastalarÄ±n verilerini derinlemesine analiz ederek anlamlÄ± Ã¶rÃ¼ntÃ¼ler ortaya Ã§Ä±karmak ve farklÄ± makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ± (Lojistik Regresyon, Random Forest, XGBoost vb.) kÄ±yaslayarak en baÅŸarÄ±lÄ± tahmin modelini geliÅŸtirmektir. Ã‡alÄ±ÅŸma kapsamÄ±nda sadece yÃ¼ksek doÄŸruluk oranlarÄ±na ulaÅŸmak deÄŸil, aynÄ± zamanda Ã¶zellik Ã¶nem analizi (feature importance) yaparak hangi klinik faktÃ¶rlerin tekrar yatÄ±ÅŸ riskini daha fazla tetiklediÄŸini belirlemek hedeflenmiÅŸtir. Elde edilen bulgularÄ±n, saÄŸlÄ±k profesyonellerine kiÅŸiselleÅŸtirilmiÅŸ taburculuk planlarÄ± hazÄ±rlama konusunda rehberlik etmesi ve gereksiz hastane yatÄ±ÅŸlarÄ±nÄ± azaltarak operasyonel verimliliÄŸe katkÄ± saÄŸlamasÄ± beklenmektedir.

## 2. VERÄ° KEÅFÄ° VE Ä°LK ANALÄ°Z

Veri analiz sÃ¼recinin ilk aÅŸamasÄ±nda, veri setinin genel yapÄ±sÄ±, Ã¶zellik daÄŸÄ±lÄ±mlarÄ± ve hedef deÄŸiÅŸkenle olan iliÅŸkileri detaylÄ± olarak incelenmiÅŸtir. Bu aÅŸama, veri kalitesini deÄŸerlendirmek ve Ã¶n iÅŸleme stratejilerini belirlemek iÃ§in kritik Ã¶nem taÅŸÄ±maktadÄ±r.

## 2.1 Veri YÃ¼kleme ve Genel Ä°nceleme

**KullanÄ±lan AraÃ§lar ve KÃ¼tÃ¼phaneler:**
- Python 3.x
- Pandas (veri manipÃ¼lasyonu)
- NumPy (sayÄ±sal hesaplamalar)
- Matplotlib ve Seaborn (gÃ¶rselleÅŸtirme)

**Veri YÃ¼kleme Ä°ÅŸlemi:**

Ä°ki ayrÄ± veri dosyasÄ± yÃ¼klenmiÅŸtir:
1. `diabetic_data.csv`: Ana veri seti (101,766 Ã— 50)
2. `IDS_mapping.csv`: ID kodlarÄ±nÄ±n aÃ§Ä±klamalarÄ±

```python
df = pd.read_csv('data/diabetic_data.csv')
mapping_df = pd.read_csv('data/IDS_mapping.csv')
```

**Veri Seti Genel Ã–zellikleri:**

| Metrik | DeÄŸer |
|--------|-------|
| **Toplam KayÄ±t SayÄ±sÄ±** | 101,766 hasta |
| **Toplam Ã–zellik SayÄ±sÄ±** | 50 deÄŸiÅŸken |
| **Bellek KullanÄ±mÄ±** | 192.87 MB |
| **Duplike KayÄ±t** | 0 (Temiz veri) |
| **Numerik Ã–zellik** | 13 deÄŸiÅŸken |
| **Kategorik Ã–zellik** | 37 deÄŸiÅŸken |

Bu bulgular, veri setinin duplikasyon iÃ§ermediÄŸini ve karma veri tiplerine sahip olduÄŸunu gÃ¶stermektedir.

### 2.2 Hedef DeÄŸiÅŸken Analizi

Hedef deÄŸiÅŸken olan `readmitted` Ã¼Ã§ kategoriye ayrÄ±lmÄ±ÅŸ durumdadÄ±r. Bu deÄŸiÅŸkenin daÄŸÄ±lÄ±mÄ± projenin sÄ±nÄ±flandÄ±rma stratejisini belirlemede temel rol oynamÄ±ÅŸtÄ±r.

**Orijinal Hedef DeÄŸiÅŸken DaÄŸÄ±lÄ±mÄ±:**

| Kategori | Hasta SayÄ±sÄ± | YÃ¼zde |
|----------|--------------|-------|
| **NO** (Tekrar yatÄ±ÅŸ yok) | 54,864 | %53.91 |
| **>30** (30 gÃ¼nden sonra) | 35,545 | %34.93 |
| **<30** (30 gÃ¼n iÃ§inde) | 11,357 | %11.16 |

**Binary DÃ¶nÃ¼ÅŸÃ¼m:**

Klinik aÃ§Ä±dan en kritik durum olan 30 gÃ¼n iÃ§indeki erken tekrar yatÄ±ÅŸlarÄ± tespit etmek amacÄ±yla hedef deÄŸiÅŸken binary formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r:

- **SÄ±nÄ±f 1 (Pozitif):** `<30` â†’ 11,357 hasta (%11.4)
- **SÄ±nÄ±f 0 (Negatif):** `>30` + `NO` â†’ 90,409 hasta (%88.6)

**Ã–nemli Bulgu:**

Veri seti **dengesiz (imbalanced)** bir daÄŸÄ±lÄ±m gÃ¶stermektedir. Pozitif sÄ±nÄ±f (30 gÃ¼n iÃ§inde tekrar yatÄ±ÅŸ) oranÄ± sadece %11.4'tÃ¼r. Bu durum, model eÄŸitimi sÄ±rasÄ±nda sÄ±nÄ±f dengeleme tekniklerinin kullanÄ±lmasÄ±nÄ± gerekli kÄ±lmÄ±ÅŸtÄ±r.

![Hedef DeÄŸiÅŸken DaÄŸÄ±lÄ±mÄ±](docs/exploratory_analysis/01_target_distribution.png)
*Åekil 2.1: Hedef deÄŸiÅŸkenin orijinal daÄŸÄ±lÄ±mÄ± (sol) ve yÃ¼zdesel oranlarÄ± (saÄŸ)*

### 2.3 Eksik DeÄŸer Analizi

Veri setinde eksik deÄŸerler `?` karakteri ile kodlanmÄ±ÅŸtÄ±r. Toplam 7 Ã¶zellikte eksik deÄŸer tespit edilmiÅŸtir.

**Eksik DeÄŸer Ä°statistikleri:**

| Ã–zellik | Eksik SayÄ± | Eksik YÃ¼zde | Karar |
|---------|------------|-------------|-------|
| **weight** | 98,569 | %96.86 | âŒ Ã‡Ä±karÄ±ldÄ± |
| **medical_specialty** | 49,949 | %49.08 | âŒ Ã‡Ä±karÄ±ldÄ± |
| **payer_code** | 40,256 | %39.56 | âŒ Ã‡Ä±karÄ±ldÄ± |
| **race** | 2,273 | %2.23 | âœ… Mode imputation |
| **diag_3** | 1,423 | %1.40 | âœ… "Missing" kategorisi |
| **diag_2** | 358 | %0.35 | âœ… "Missing" kategorisi |
| **diag_1** | 21 | %0.02 | âœ… Mode imputation |


<div style="
    border-left: 5px solid #2196F3;
    background-color: #E3F2FD;
    padding: 10px;
    margin: 10px 0;
">
<strong>â„¹ï¸ Bilgi</strong><br>
    
1. **YÃ¼ksek Oranda Eksik Ã–zellikler (>40%):** `weight`, `medical_specialty`, ve `payer_code` Ã¶zellikleri, eksiklik oranÄ±nÄ±n Ã§ok yÃ¼ksek olmasÄ± nedeniyle veri setinden Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r.

2. **DÃ¼ÅŸÃ¼k Oranda Eksik Ã–zellikler (<5%):** `race` ve `diag_1` iÃ§in en sÄ±k gÃ¶rÃ¼len deÄŸer (mode) ile doldurma iÅŸlemi uygulanmÄ±ÅŸtÄ±r.

3. **TeÅŸhis KodlarÄ±:** `diag_2` ve `diag_3` iÃ§in eksik deÄŸerler "Missing" kategorisi olarak iÅŸaretlenmiÅŸtir Ã§Ã¼nkÃ¼ eksikliÄŸin kendisi klinik bir bilgi taÅŸÄ±yabilir.
</div>



![Eksik DeÄŸerler Analizi](docs/exploratory_analysis/02_missing_values.png)
*Åekil 2.2: Ã–zelliklerdeki eksik deÄŸer yÃ¼zdeleri*

### 2.4 Numerik Ã–zellikler Analizi

Veri setinde 13 numerik Ã¶zellik bulunmaktadÄ±r. Bu Ã¶zellikler hastane yatÄ±ÅŸ sÃ¼releri, yapÄ±lan testler ve prosedÃ¼rleri temsil etmektedir.

**Ã–nemli Numerik Ã–zellikler:**

| Ã–zellik | Ortalama | Medyan | Std. Sapma | Min | Max |
|---------|----------|--------|------------|-----|-----|
| **time_in_hospital** | 4.40 | 4.0 | 2.99 | 1 | 14 |
| **num_lab_procedures** | 43.10 | 44.0 | 19.67 | 1 | 132 |
| **num_procedures** | 1.34 | 1.0 | 1.71 | 0 | 6 |
| **num_medications** | 16.02 | 15.0 | 8.13 | 1 | 81 |
| **number_diagnoses** | 7.42 | 8.0 | 1.93 | 1 | 16 |
| **number_outpatient** | 0.37 | 0.0 | 1.27 | 0 | 42 |
| **number_emergency** | 0.20 | 0.0 | 0.93 | 0 | 76 |
| **number_inpatient** | 0.64 | 0.0 | 1.26 | 0 | 21 |

<div style="
    border-left: 5px solid #FF9800;
    background-color: #FFF3E0;
    padding: 10px;
    margin: 10px 0;
">
<strong>ğŸ¦‰ GÃ¶zlemler</strong><br>
    
1. **Hastanede KalÄ±ÅŸ SÃ¼resi:** Ortalama 4.4 gÃ¼n, maksimum 14 gÃ¼n. DaÄŸÄ±lÄ±m saÄŸa Ã§arpÄ±k (right-skewed).

2. **Laboratuvar Testleri:** Ortalama 43 test yapÄ±lmÄ±ÅŸ, bu oldukÃ§a yÃ¼ksek bir deÄŸer. HastalarÄ±n karmaÅŸÄ±k durumlarÄ±nÄ± gÃ¶steriyor.

3. **Ä°laÃ§ SayÄ±sÄ±:** Ortalama 16 farklÄ± ilaÃ§ kullanÄ±mÄ±, diabetes'in Ã§oklu ilaÃ§ tedavisi gerektirdiÄŸini doÄŸruluyor.

4. **Ã–nceki BaÅŸvurular:** Ã‡oÄŸu hastanÄ±n Ã¶nceden acil servis veya ayakta tedavi baÅŸvurusu yok (medyan = 0).

5. **TeÅŸhis SayÄ±sÄ±:** Ortalama 7.4 teÅŸhis kodu, hastalarÄ±n Ã§oklu kronik hastalÄ±klara sahip olduÄŸunu gÃ¶steriyor.
</div>

![Numerik DaÄŸÄ±lÄ±mlar](docs/exploratory_analysis/03_numeric_distributions.png)
*Åekil 2.3: Ã–nemli numerik Ã¶zelliklerin daÄŸÄ±lÄ±mlarÄ± (histogram ve istatistiksel Ã§izgiler)*

### 2.5 Kategorik Ã–zellikler Analizi

Veri setinde 37 kategorik Ã¶zellik bulunmaktadÄ±r. Bu Ã¶zellikler demografik bilgiler, kabul/taburculuk bilgileri ve ilaÃ§ kullanÄ±m durumlarÄ±nÄ± iÃ§ermektedir.

**En Fazla Kategoriye Sahip Ã–zellikler:**

| Ã–zellik | Benzersiz Kategori | En SÄ±k DeÄŸer | YÃ¼zde |
|---------|-------------------|--------------|-------|
| **diag_1** (Birincil teÅŸhis) | 717 | 428 (Kalp yetmezliÄŸi) | %6.74 |
| **diag_2** (Ä°kincil teÅŸhis) | 749 | 276 (SÄ±vÄ± elektrolit bozukluÄŸu) | %6.63 |
| **diag_3** (ÃœÃ§Ã¼ncÃ¼l teÅŸhis) | 790 | 250 (Diabetes mellitus) | %11.35 |
| **age** | 10 | [70-80) | %25.62 |
| **race** | 6 | Caucasian | %74.78 |
| **gender** | 3 | Female/Male | - |

**Demografik Bulgular:**

1. **YaÅŸ DaÄŸÄ±lÄ±mÄ±:** HastalarÄ±n %25.6'sÄ± 70-80 yaÅŸ grubunda. YaÅŸlÄ± popÃ¼lasyon aÄŸÄ±rlÄ±klÄ±.

2. **Irk:** HastalarÄ±n %74.8'i Caucasian (Beyaz Ä±rk), veri seti demografik olarak homojen.

3. **Cinsiyet:** KadÄ±n-erkek daÄŸÄ±lÄ±mÄ± dengeli.


**Ä°laÃ§ KullanÄ±m Analizi:**

23 farklÄ± diabetes ilacÄ± iÃ§in kullanÄ±m durumu kaydedilmiÅŸtir. Her ilaÃ§ iÃ§in deÄŸiÅŸiklik durumu (No, Up, Down, Steady) belirtilmiÅŸtir.

| Ä°laÃ§ | KullanÄ±m OranÄ± | Yorum |
|------|----------------|-------|
| **insulin** | %53.44 | En yaygÄ±n ilaÃ§ |
| **metformin** | %19.64 | Ä°kinci sÄ±rada |
| **glipizide** | %12.47 | ÃœÃ§Ã¼ncÃ¼ sÄ±rada |
| **glyburide** | %10.47 | DÃ¶rdÃ¼ncÃ¼ sÄ±rada |
| **pioglitazone** | %7.20 | - |
| **rosiglitazone** | %6.25 | - |

![Kategorik DaÄŸÄ±lÄ±mlar](docs/exploratory_analysis/04_categorical_distributions.png)
*Åekil 2.4: Ã–nemli kategorik Ã¶zelliklerin frekans daÄŸÄ±lÄ±mlarÄ±*

![Ä°laÃ§ KullanÄ±mÄ±](docs/exploratory_analysis/08_medication_usage.png)
*Åekil 2.5: Diabetes ilaÃ§larÄ±nÄ±n kullanÄ±m yÃ¼zdeleri*

### 2.6 Hedef DeÄŸiÅŸken ile Ã–zellik Ä°liÅŸkileri

Ã–zellikler ile hedef deÄŸiÅŸken (`readmitted`) arasÄ±ndaki iliÅŸkiler incelenmiÅŸ ve potansiyel tahmin ediciler belirlenmiÅŸtir.

**Numerik Ã–zellikler vs Hedef DeÄŸiÅŸken:**

Box plot analizleri ile numerik Ã¶zelliklerin readmission durumuna gÃ¶re daÄŸÄ±lÄ±mlarÄ± karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r:

- **number_inpatient:** 30 gÃ¼n iÃ§inde tekrar yatÄ±ÅŸ yapanlarÄ±n Ã¶nceki yatÄ±ÅŸ sayÄ±sÄ± daha yÃ¼ksek
- **number_emergency:** Acil baÅŸvuru geÃ§miÅŸi olan hastalarda risk artÄ±ÅŸÄ±
- **time_in_hospital:** Ä°lk yatÄ±ÅŸ sÃ¼resi ile tekrar yatÄ±ÅŸ arasÄ±nda iliÅŸki gÃ¶zlemlenmiÅŸ
- **num_medications:** Ã‡oklu ilaÃ§ kullananlar daha riskli

![Numerik vs Target](docs/exploratory_analysis/05_numeric_vs_target.png)
*Åekil 2.6: Numerik Ã¶zelliklerin readmission durumuna gÃ¶re kutu grafikleri*

**Kategorik Ã–zellikler vs Hedef DeÄŸiÅŸken:**

Ã‡apraz tablolar (crosstab) ile kategorik Ã¶zelliklerin readmission oranlarÄ± analiz edilmiÅŸtir:

- **age:** GenÃ§ (<30) ve Ã§ok yaÅŸlÄ± (>80) hastalarda risk deÄŸiÅŸiyor
- **gender:** Cinsiyet faktÃ¶rÃ¼ minimal etki gÃ¶steriyor
- **diabetesMed:** Diabetes ilacÄ± kullanÄ±mÄ± readmission ile iliÅŸkili
- **race:** Irk gruplarÄ± arasÄ±nda farklÄ±lÄ±klar var

![Kategorik vs Target](docs/exploratory_analysis/06_categorical_vs_target.png)
*Åekil 2.7: Kategorik Ã¶zelliklerin readmission durumuna gÃ¶re yÃ¼zdesel daÄŸÄ±lÄ±mlarÄ±*


### 2.7 Korelasyon Analizi

Numerik Ã¶zellikler arasÄ±ndaki korelasyonlar incelenmiÅŸ ve multicollinearity (Ã§oklu doÄŸrusal baÄŸlantÄ±) riski deÄŸerlendirilmiÅŸtir.

**Korelasyon Matrisi BulgularÄ±:**

- YÃ¼ksek korelasyonlu Ã¶zellik Ã§ifti (**|r| > 0.7**): **0 adet**
- Bu bulgu, modelleme aÅŸamasÄ±nda Ã¶zellik Ã§Ä±karma ihtiyacÄ±nÄ±n dÃ¼ÅŸÃ¼k olduÄŸunu gÃ¶stermektedir

**Orta DÃ¼zeyde Korelasyonlar:**

- `num_medications` ve `num_lab_procedures` arasÄ±nda pozitif korelasyon
- `time_in_hospital` ile prosedÃ¼r sayÄ±larÄ± arasÄ±nda beklenen iliÅŸkiler

![Korelasyon Matrisi](docs/exploratory_analysis/07_correlation_matrix.png)
*Åekil 2.8: Numerik Ã¶zelliklerin korelasyon Ä±sÄ± haritasÄ±*

### 2.8 Veri KeÅŸfi SonuÃ§larÄ± ve Ã‡Ä±karÄ±mlar

Veri keÅŸfi sÃ¼recinden elde edilen temel bulgular, modelleme aÅŸamasÄ± iÃ§in stratejik bir yol haritasÄ± sunmaktadÄ±r. Analizler sonucunda veri setinde duplikasyon saptanmamÄ±ÅŸ, mevcut eksik deÄŸerler iÃ§in ise verinin doÄŸasÄ±na uygun yÃ¶netim stratejileri belirlenmiÅŸtir. Ancak, pozitif sÄ±nÄ±f oranÄ±nÄ±n %11,4 seviyesinde kalmasÄ± belirgin bir sÄ±nÄ±f dengesizliÄŸine iÅŸaret etmekte; bu durum SMOTE veya sÄ±nÄ±f aÄŸÄ±rlÄ±klandÄ±rma gibi tekniklerin kullanÄ±mÄ±nÄ± zorunlu kÄ±lmaktadÄ±r. 50 farklÄ± Ã¶znitelik ile zengin bir klinik ve demografik veri yapÄ±sÄ± sunan projede, 700'den fazla kategori iÃ§eren teÅŸhis kodlarÄ±nÄ±n yÃ¼ksek kardinalite sorunu, kritik bir kodlama (encoding) stratejisinin geliÅŸtirilmesini gerektirmektedir. SonuÃ§ olarak, hastalarÄ±n geÃ§miÅŸ baÅŸvurularÄ±, ilaÃ§ kullanÄ±m alÄ±ÅŸkanlÄ±klarÄ± ve hastanede kalÄ±ÅŸ sÃ¼releri ile tekrar yatÄ±ÅŸ riski arasÄ±nda saptanan anlamlÄ± iliÅŸkiler, bu deÄŸiÅŸkenlerin modelin tahmin gÃ¼cÃ¼ Ã¼zerinde yÃ¼ksek bir potansiyele sahip olduÄŸunu doÄŸrulamaktadÄ±r.

## 3. VERÄ° Ã–N Ä°ÅLEME

Veri keÅŸfi aÅŸamasÄ±nda belirlenen stratejiler doÄŸrultusunda, veri seti model eÄŸitimine hazÄ±r hale getirilmiÅŸtir. Bu aÅŸamada veri temizleme, eksik deÄŸer yÃ¶netimi, Ã¶zellik mÃ¼hendisliÄŸi ve Ã¶lÃ§eklendirme iÅŸlemleri sistematik olarak uygulanmÄ±ÅŸtÄ±r.

### 3.1 Veri Temizleme Ä°ÅŸlemleri

**3.1.1 Duplikasyon KontrolÃ¼**

Veri setinde duplike satÄ±r kontrolÃ¼ yapÄ±lmÄ±ÅŸtÄ±r:
- **Ã‡Ä±karÄ±lan duplike satÄ±r:** 0
- **SonuÃ§:** Veri seti zaten temiz durumdadÄ±r

**3.1.2 Gereksiz SÃ¼tunlarÄ±n Ã‡Ä±karÄ±lmasÄ±**

Model eÄŸitimi iÃ§in uygun olmayan sÃ¼tunlar veri setinden Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r:

| SÃ¼tun | Ã‡Ä±karÄ±lma GerekÃ§esi |
|-------|---------------------|
| `encounter_id` | Sadece tanÄ±mlayÄ±cÄ±, tahmin gÃ¼cÃ¼ yok |
| `patient_nbr` | Sadece tanÄ±mlayÄ±cÄ±, tahmin gÃ¼cÃ¼ yok |
| `weight` | %96.86 eksik deÄŸer, kullanÄ±lamaz |
| `payer_code` | %39.56 eksik deÄŸer, dÃ¼ÅŸÃ¼k tahmin gÃ¼cÃ¼ |
| `medical_specialty` | %49.08 eksik deÄŸer, yÃ¼ksek kardinalite |
| `readmitted` | Binary versiyonu (`readmitted_binary`) kullanÄ±lacak |


**SonuÃ§:** 6 sÃ¼tun Ã§Ä±karÄ±lmÄ±ÅŸ, 44 sÃ¼tun korunmuÅŸtur.

### 3.2 Hedef DeÄŸiÅŸken DÃ¶nÃ¼ÅŸÃ¼mÃ¼

**DÃ¶nÃ¼ÅŸÃ¼m Stratejisi:**

Orijinal hedef deÄŸiÅŸken `readmitted` Ã¼Ã§ kategoriye sahipti (NO, >30, <30). Klinik aÃ§Ä±dan en kritik olan 30 gÃ¼n iÃ§indeki erken tekrar yatÄ±ÅŸlarÄ± tespit etmek iÃ§in binary dÃ¶nÃ¼ÅŸÃ¼m uygulanmÄ±ÅŸtÄ±r.

**DÃ¶nÃ¼ÅŸÃ¼m KuralÄ±:**
```python
readmitted_binary = 1 if readmitted == '<30' else 0
```

**DÃ¶nÃ¼ÅŸÃ¼m SonrasÄ± DaÄŸÄ±lÄ±m:**

| SÄ±nÄ±f | AÃ§Ä±klama | Hasta SayÄ±sÄ± | YÃ¼zde |
|-------|----------|--------------|-------|
| **0** | 30 gÃ¼nden sonra veya yatÄ±ÅŸ yok | 90,409 | %88.84 |
| **1** | 30 gÃ¼n iÃ§inde tekrar yatÄ±ÅŸ | 11,357 | %11.16 |

<div style="
    border-left: 5px solid #7B1FA2;
    background-color: #F3E5F5;
    padding: 12px 14px;
    margin: 12px 0;
    border-radius: 4px;
">
<strong>ğŸ“ Ã–nemli Not</strong><br>
Veri seti dengesiz (imbalanced) bir yapÄ±ya sahiptir. Model eÄŸitimi sÄ±rasÄ±nda bu dengesizliÄŸi gidermek iÃ§in:
    
- SMOTE (Synthetic Minority Over-sampling Technique)
- Class weight ayarlamalarÄ±
- Stratified cross-validation
  
teknikleri kullanÄ±lacaktÄ±r.
</div>



![Hedef DeÄŸiÅŸken DÃ¶nÃ¼ÅŸÃ¼mÃ¼](docs/preprocessing/02_target_transformation.png)
*Åekil 3.1: Orijinal hedef deÄŸiÅŸken (sol) ve binary dÃ¶nÃ¼ÅŸÃ¼m sonrasÄ± (saÄŸ)*


### 3.3 Eksik DeÄŸer YÃ¶netimi

Veri setinde `?` karakteri ile kodlanmÄ±ÅŸ eksik deÄŸerler tespit edilmiÅŸ ve sistematik olarak yÃ¶netilmiÅŸtir.

**3.3.1 Uygulanan Strateji:**

1. **YÃ¼ksek Oranda Eksik (>50%):** SÃ¼tun tamamen Ã§Ä±karÄ±lÄ±r
2. **Kategorik DeÄŸiÅŸkenler (<50%):** Mode (en sÄ±k deÄŸer) ile doldurulur
3. **Numerik DeÄŸiÅŸkenler (<50%):** Median ile doldurulur
4. **TeÅŸhis KodlarÄ±:** "Missing" kategorisi olarak iÅŸaretlenir (eksiklik bilgi taÅŸÄ±yabilir)

**3.3.2 YÃ¼ksek EksikliÄŸe Sahip Ã‡Ä±karÄ±lan SÃ¼tunlar:**

- `max_glu_serum`: %94+ eksik
- `A1Cresult`: %83+ eksik

Bu sÃ¼tunlar eksiklik oranÄ±nÄ±n Ã§ok yÃ¼ksek olmasÄ± nedeniyle imputation yerine tamamen Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r.

**3.3.3 Doldurma Ä°ÅŸlemleri:**

**Kategorik DeÄŸiÅŸkenler (Mode Imputation):**
- `race`: En sÄ±k deÄŸer "Caucasian" ile dolduruldu
- `diag_1`, `diag_2`, `diag_3`: Mode deÄŸerleri ile dolduruldu

**Numerik DeÄŸiÅŸkenler (Median Imputation):**
- Numerik Ã¶zelliklerde minimal eksiklik tespit edildi
- Median kullanÄ±larak outlier'lardan etkilenmeden doldurma yapÄ±ldÄ±

**SonuÃ§:** TÃ¼m eksik deÄŸerler baÅŸarÄ±yla yÃ¶netildi. 

**Kalan toplam eksik deÄŸer: 0**


### 3.4 Ã–zellik MÃ¼hendisliÄŸi (Feature Engineering)

Veri setinin tahmin gÃ¼cÃ¼nÃ¼ artÄ±rmak amacÄ±yla domain knowledge (alan bilgisi) kullanÄ±larak 8 yeni Ã¶zellik oluÅŸturulmuÅŸtur.

**3.4.1 OluÅŸturulan Yeni Ã–zellikler:**

| # | Ã–zellik AdÄ± | FormÃ¼l/MantÄ±k | GerekÃ§e |
|---|-------------|---------------|---------|
| 1 | `age_numeric` | YaÅŸ kategorileri â†’ sayÄ±sal deÄŸer | Model iÃ§in sÃ¼rekli deÄŸiÅŸken daha etkili |
| 2 | `num_medications_changed` | Î£(ilaÃ§ â‰  'No') | Tedavi deÄŸiÅŸikliÄŸi readmission ile iliÅŸkili |
| 3 | `total_procedures` | lab_procedures + procedures | Toplam medikal mÃ¼dahale yoÄŸunluÄŸu |
| 4 | `has_emergency_history` | (emergency > 0) OR (inpatient > 0) | Kronik hastalÄ±k ciddiyet gÃ¶stergesi |
| 5 | `on_diabetes_med` | diabetesMed == 'Yes' | HastalÄ±k yÃ¶netimi gÃ¶stergesi |
| 6 | `med_changed` | change == 'Ch' | Tedavi etkinliÄŸi/uyum gÃ¶stergesi |
| 7 | `procedure_intensity` | procedures / (time_in_hospital + 1) | GÃ¼nlÃ¼k prosedÃ¼r yoÄŸunluÄŸu (normalize) |
| 8 | `medication_intensity` | medications / (time_in_hospital + 1) | GÃ¼nlÃ¼k ilaÃ§ yoÄŸunluÄŸu (normalize) |

**3.4.2 YaÅŸ Kategorisi DÃ¶nÃ¼ÅŸÃ¼mÃ¼:**

Orijinal yaÅŸ kategorileri sayÄ±sal deÄŸerlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r:
```python
age_mapping = {
    '[0-10)': 5,   '[10-20)': 15,  '[20-30)': 25,  '[30-40)': 35,  '[40-50)': 45,
    '[50-60)': 55, '[60-70)': 65,  '[70-80)': 75,  '[80-90)': 85,  '[90-100)': 95
}
```


u dÃ¶nÃ¼ÅŸÃ¼m, yaÅŸ ile readmission riski arasÄ±ndaki non-linear iliÅŸkiyi modellerin Ã¶ÄŸrenmesini kolaylaÅŸtÄ±rmaktadÄ±r.

**3.4.3 TeÅŸhis Kodu (Diagnosis Code) Engineering:**

ICD-9 teÅŸhis kodlarÄ± 700+ benzersiz deÄŸere sahip olduÄŸu iÃ§in:

1. **Kategori Ã‡Ä±karÄ±mÄ±:** Ä°lk 3 rakam ana hastalÄ±k kategorisini gÃ¶sterir
2. **Frequency Encoding:** Her kategorinin veri setindeki sÄ±klÄ±ÄŸÄ± hesaplanmÄ±ÅŸtÄ±r

```python
diag_1_category = str(diag_1)[:3]  # Ã–rn: "428" â†’ Kalp yetmezliÄŸi
diag_1_freq = category_frequency_in_dataset
```

Bu yÃ¶ntem, yÃ¼ksek kardinaliteyi azaltÄ±rken klinik bilgiyi korumaktadÄ±r.

![Ã–n Ä°ÅŸleme Ã–zeti](docs/preprocessing/01_preprocessing_summary.png)
*Åekil 3.4: Ã–n iÅŸleme aÅŸamalarÄ±nda Ã¶zellik sayÄ±sÄ±nÄ±n deÄŸiÅŸimi ve yeni oluÅŸturulan Ã¶zellikler*

### 3.5 Kategorik DeÄŸiÅŸken Encoding

Makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ±n kategorik deÄŸiÅŸkenleri iÅŸleyebilmesi iÃ§in numerik formata dÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemleri uygulanmÄ±ÅŸtÄ±r.

**3.5.1 Binary Encoding**

Ä°ki kategorili deÄŸiÅŸkenler iÃ§in basit 0/1 encoding:
- `gender`: Male=0, Female=1

**3.5.2 One-Hot Encoding**

Nominal (sÄ±ralÄ± olmayan) kategorik deÄŸiÅŸkenler iÃ§in:
- `race`: 6 Ä±rk kategorisi â†’ 5 dummy variable (drop_first=True)
  - `race_AfricanAmerican`, `race_Asian`, `race_Caucasian`, `race_Hispanic`, `race_Other`

Bu yÃ¶ntem, kategoriler arasÄ± yapay sÄ±ralama oluÅŸturmayÄ± Ã¶nler.

**3.5.3 Label Encoding**

ID bazlÄ± ordinal deÄŸiÅŸkenler iÃ§in:
- `admission_type_id`: 8 kategori â†’ 0-7 arasÄ± sayÄ±lar
- `discharge_disposition_id`: 29 kategori â†’ 0-28 arasÄ± sayÄ±lar  
- `admission_source_id`: 21 kategori â†’ 0-20 arasÄ± sayÄ±lar

**3.5.4 Ä°laÃ§ DeÄŸiÅŸkenleri iÃ§in Ordinal Encoding**

23 farklÄ± diabetes ilacÄ± iÃ§in deÄŸiÅŸiklik durumu ordinal olarak kodlanmÄ±ÅŸtÄ±r:

| Orijinal DeÄŸer | Encoded DeÄŸer | AnlamÄ± |
|----------------|---------------|--------|
| No | 0 | Ä°laÃ§ kullanÄ±lmÄ±yor |
| Steady | 1 | Ä°laÃ§ kullanÄ±lÄ±yor, doz deÄŸiÅŸmedi |
| Up | 2 | Doz artÄ±rÄ±ldÄ± |
| Down | 3 | Doz azaltÄ±ldÄ± |

Bu encoding, ilaÃ§ deÄŸiÅŸikliÄŸinin yÃ¶nÃ¼nÃ¼ ve ÅŸiddetini korumaktadÄ±r.

**3.5.5 Encoding SonrasÄ± Temizlik**

Encoding iÅŸlemlerinden sonra orijinal kategorik sÃ¼tunlar veri setinden Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r:
- `age`, `race`, `diabetesMed`, `change`
- `diag_1`, `diag_2`, `diag_3` (frequency encodings korundu)

### 3.6 AykÄ±rÄ± DeÄŸer (Outlier) YÃ¶netimi

**3.6.1 Tespit Metodu: IQR (Interquartile Range)**

AykÄ±rÄ± deÄŸer tespiti iÃ§in istatistiksel olarak robust bir yÃ¶ntem olan IQR kullanÄ±lmÄ±ÅŸtÄ±r:

```
Q1 = 25. persentil
Q3 = 75. persentil
IQR = Q3 - Q1
Lower Bound = Q1 - 3Ã—IQR
Upper Bound = Q3 + 3Ã—IQR
```

<div style="
    border-left: 5px solid #7B1FA2;
    background-color: #F3E5F5;
    padding: 12px 14px;
    margin: 12px 0;
    border-radius: 4px;
">
<strong>ğŸ“ Not</strong><br>

Standart 1.5Ã—IQR yerine 3Ã—IQR kullanÄ±larak daha toleranslÄ± bir yaklaÅŸÄ±m benimsenmiÅŸtir.
</div>

**3.6.2 Tespit Edilen Outlier Ä°statistikleri:**

Toplam 29 Ã¶zellikte aykÄ±rÄ± deÄŸer tespit edilmiÅŸtir.

**En Ã‡ok Outlier Ä°Ã§eren Top 10 Ã–zellik:**

| Ã–zellik | Outlier SayÄ±sÄ± | YÃ¼zde |
|---------|----------------|-------|
| `on_diabetes_med` | 23,403 | %23.00 |
| `metformin` | 19,988 | %19.64 |
| `number_outpatient` | 16,739 | %16.45 |
| `glipizide` | 12,686 | %12.47 |
| `number_emergency` | 11,383 | %11.19 |
| `glyburide` | 10,650 | %10.47 |
| `pioglitazone` | 7,328 | %7.20 |
| `rosiglitazone` | 6,365 | %6.25 |
| `glimepiride` | 5,191 | %5.10 |
| `procedure_intensity` | 2,808 | %2.76 |

**3.6.3 Outlier YÃ¶netim KararÄ±:**

AykÄ±rÄ± deÄŸerler **veri setinde bÄ±rakÄ±lmÄ±ÅŸtÄ±r**. Bu karar aÅŸaÄŸÄ±daki gerekÃ§elere dayanmaktadÄ±r:

1. **Klinik AnlamlÄ±lÄ±k:** Medikal verilerde extreme deÄŸerler, ciddi hastalÄ±k durumlarÄ±nÄ± veya karmaÅŸÄ±k vakalarÄ± temsil edebilir

2. **Tahmin Edici DeÄŸer:** YÃ¼ksek ilaÃ§ kullanÄ±mÄ± veya sÄ±k hastane baÅŸvurusu, readmission riski ile gÃ¼Ã§lÃ¼ iliÅŸkili olabilir

3. **Veri KaybÄ± Riski:** Outlier'larÄ± Ã§Ä±karmak, Ã¶nemli klinik patternlerin kaybolmasÄ±na neden olabilir

4. **Robust Ã–lÃ§eklendirme:** Sonraki aÅŸamada StandardScaler kullanÄ±mÄ±, outlier'larÄ±n model Ã¼zerindeki negatif etkisini azaltacaktÄ±r

### 3.7 Ã–zellik Ã–lÃ§eklendirme (Feature Scaling)

**3.7.1 Ã–lÃ§eklendirme Gereksinimi**

FarklÄ± Ã¶zelliklerin farklÄ± Ã¶lÃ§eklerde olmasÄ± (Ã¶rn: yaÅŸ 1-100, laboratuvar testi sayÄ±sÄ± 1-132), gradient-based algoritmalar iÃ§in problem oluÅŸturabilir. Ã–lÃ§eklendirme:
- Modellerin daha hÄ±zlÄ± convergence saÄŸlamasÄ±nÄ±
- UzaklÄ±k bazlÄ± algoritmalarÄ±n (KNN, SVM) doÄŸru Ã§alÄ±ÅŸmasÄ±nÄ±
- DÃ¼zenli (regularization) terimlerin adil uygulanmasÄ±nÄ±

saÄŸlamaktadÄ±r.

**3.7.2 SeÃ§ilen YÃ¶ntem: StandardScaler (Z-Score Normalization)**

StandardScaler, her Ã¶zelliÄŸi ortalamasÄ± 0, standart sapmasÄ± 1 olacak ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r:

$$z = \frac{x - \mu}{\sigma}$$

Burada:
- $x$: Orijinal deÄŸer
- $\mu$: Ã–zelliÄŸin ortalamasÄ±
- $\sigma$: Ã–zelliÄŸin standart sapmasÄ±
- $z$: Ã–lÃ§eklendirilmiÅŸ deÄŸer

**3.7.3 Ã–lÃ§eklendirme Ä°statistikleri:**

- **Ã–lÃ§eklendirilen Ã¶zellik sayÄ±sÄ±:** 44
- **Hedef deÄŸiÅŸken:** Ã–lÃ§eklendirmeye dahil edilmemiÅŸtir (binary 0/1 olarak korunmuÅŸtur)

**3.7.4 Scaler Objesinin Kaydedilmesi:**

EÄŸitim verisinde fit edilen scaler objesi `scaler.pkl` dosyasÄ±na kaydedilmiÅŸtir. Bu, gelecekte yeni verilerin aynÄ± parametrelerle Ã¶lÃ§eklendirilmesini saÄŸlar (train-test consistency).

![Ã–lÃ§eklendirilmiÅŸ Ã–zellikler](docs/preprocessing/03_scaled_features_distribution.png)
*Åekil 3.7: Ã–lÃ§eklendirme sonrasÄ± Ã¶zelliklerin daÄŸÄ±lÄ±mlarÄ± (ortalama=0 etrafÄ±nda merkezlenmiÅŸ)*

## 4. MODEL EÄÄ°TÄ°MÄ°

Veri Ã¶n iÅŸleme aÅŸamasÄ± tamamlandÄ±ktan sonra, diabetik hastalarÄ±n 30 gÃ¼n iÃ§inde hastaneye tekrar yatÄ±ÅŸ riskini tahmin etmek Ã¼zere 5 farklÄ± makine Ã¶ÄŸrenmesi modeli eÄŸitilmiÅŸtir. Bu bÃ¶lÃ¼mde train-test split stratejisi, sÄ±nÄ±f dengeleme yÃ¶ntemleri, model seÃ§imi ve eÄŸitim sÃ¼reci detaylÄ± olarak aÃ§Ä±klanmÄ±ÅŸtÄ±r.

### 4.1 Train-Test Split Stratejisi

**4.1.1 BÃ¶lme OranÄ± ve YÃ¶ntem**

Veri seti, modelin genelleme yeteneÄŸini deÄŸerlendirmek iÃ§in eÄŸitim ve test setlerine ayrÄ±lmÄ±ÅŸtÄ±r:

| Set | Ã–rnek SayÄ±sÄ± | YÃ¼zde | AmaÃ§ |
|-----|--------------|-------|------|
| **Train** | 81,412 | %80 | Model eÄŸitimi |
| **Test** | 20,354 | %20 | Model deÄŸerlendirme |

**KullanÄ±lan YÃ¶ntem:** `Stratified Split`

Stratified split, hedef deÄŸiÅŸkenin sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ±n hem train hem de test setinde korunmasÄ±nÄ± saÄŸlar. Bu, Ã¶zellikle dengesiz veri setlerinde kritik Ã¶neme sahiptir.

**4.1.2 Train ve Test Setlerinde SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±**

**Train Set:**
- SÄ±nÄ±f 0 (YatÄ±ÅŸ yok/geÃ§): 72,326 (%88.84)
- SÄ±nÄ±f 1 (30 gÃ¼n iÃ§inde yatÄ±ÅŸ): 9,086 (%11.16)

**Test Set:**
- SÄ±nÄ±f 0 (YatÄ±ÅŸ yok/geÃ§): 18,083 (%88.84)
- SÄ±nÄ±f 1 (30 gÃ¼n iÃ§inde yatÄ±ÅŸ): 2,271 (%11.16)

Her iki sette de sÄ±nÄ±f oranlarÄ± korunmuÅŸtur (%88.84 vs %11.16), bu da stratified split'in baÅŸarÄ±lÄ± uygulandÄ±ÄŸÄ±nÄ± gÃ¶stermektedir.

### 4.2 Class Imbalance Handling (SÄ±nÄ±f Dengeleme)

**4.2.1 Problem TanÄ±mÄ±**

Veri setinde ciddi bir sÄ±nÄ±f dengesizliÄŸi bulunmaktadÄ±r:
- **Imbalance Ratio:** 7.96:1 (Negatif sÄ±nÄ±f / Pozitif sÄ±nÄ±f)

Bu dengesizlik, modellerin Ã§oÄŸunluk sÄ±nÄ±fÄ±na (SÄ±nÄ±f 0) bias gÃ¶stermesine ve azÄ±nlÄ±k sÄ±nÄ±fÄ±nÄ± (SÄ±nÄ±f 1 - kritik hastalar) doÄŸru tahmin edememesine neden olabilir.

**4.2.2 Uygulanan YÃ¶ntem: SMOTE + Random Undersampling**

SÄ±nÄ±f dengesizliÄŸini gidermek iÃ§in hibrit bir yaklaÅŸÄ±m benimsenmiÅŸtir:

**1. SMOTE (Synthetic Minority Over-sampling Technique):**
- AzÄ±nlÄ±k sÄ±nÄ±fÄ± (SÄ±nÄ±f 1) sentetik Ã¶rnekler oluÅŸturarak artÄ±rÄ±lmÄ±ÅŸtÄ±r
- Sampling strategy: 0.5 (AzÄ±nlÄ±k sÄ±nÄ±fÄ± %50 oranÄ±na Ã§Ä±karÄ±ldÄ±)
- YÃ¶ntem: K-nearest neighbors kullanarak sentetik Ã¶rnekler Ã¼retildi

**2. Random Undersampling:**
- Ã‡oÄŸunluk sÄ±nÄ±fÄ± (SÄ±nÄ±f 0) rastgele Ã¶rnekler Ã§Ä±karÄ±larak azaltÄ±lmÄ±ÅŸtÄ±r
- Sampling strategy: 0.8 (Ã‡oÄŸunluk sÄ±nÄ±fÄ± %80 oranÄ±na Ã§ekildi)

**4.2.3 Resampling SonuÃ§larÄ±**

**Resampled Train Set:**
- SÄ±nÄ±f 0: 45,203 (%55.56)
- SÄ±nÄ±f 1: 36,163 (%44.44)
- **Yeni Imbalance Ratio:** 1.25:1

SÄ±nÄ±f dengesi 7.96:1 oranÄ±ndan 1.25:1 oranÄ±na iyileÅŸtirilmiÅŸtir. Bu dengeli veri seti, modellerin her iki sÄ±nÄ±fÄ± da daha iyi Ã¶ÄŸrenmesini saÄŸlamÄ±ÅŸtÄ±r.

![Class Balance](docs/model_training/01_class_balance.png)
*Åekil 4.2: Orijinal train set (sol) ve SMOTE+Undersampling sonrasÄ± (saÄŸ) sÄ±nÄ±f daÄŸÄ±lÄ±mlarÄ±*

<div style="
    border-left: 5px solid #7B1FA2;
    background-color: #F3E5F5;
    padding: 12px 14px;
    margin: 12px 0;
    border-radius: 4px;
">
<strong>ğŸ“ Ã–nemli Not</strong><br>
SMOTE ve undersampling yalnÄ±zca train set'e uygulanmÄ±ÅŸtÄ±r. Test set, modelin gerÃ§ek dÃ¼nya performansÄ±nÄ± deÄŸerlendirmek iÃ§in orijinal dengesiz daÄŸÄ±lÄ±mÄ± ile korunmuÅŸtur.
</div>

### 4.3 Model SeÃ§imi ve Hiperparametreler

Derste iÅŸlenen temel algoritmalar ve state-of-the-art yÃ¶ntemler olmak Ã¼zere 5 farklÄ± model eÄŸitilmiÅŸtir. Her modelin seÃ§im gerekÃ§esi ve kullanÄ±lan hiperparametreleri aÅŸaÄŸÄ±da detaylandÄ±rÄ±lmÄ±ÅŸtÄ±r.

**4.3.1 Logistic Regression (Baseline Model)**

DoÄŸrusal ve yorumlanabilir yapÄ±sÄ± sayesinde, diÄŸer karmaÅŸÄ±k modellerin performansÄ±nÄ± Ã¶lÃ§mek iÃ§in temel bir referans (baseline) noktasÄ± oluÅŸturmasÄ± amacÄ±yla seÃ§ilmiÅŸtir. Modelin katsayÄ± analizi sunmasÄ±, klinik deÄŸiÅŸkenlerin risk Ã¼zerindeki doÄŸrudan etkilerinin ÅŸeffaf bir ÅŸekilde deÄŸerlendirilmesine olanak tanÄ±maktadÄ±r.

**Hiperparametreler:**
- `solver`: 'liblinear' (KÃ¼Ã§Ã¼k veri setleri iÃ§in optimize)
- `max_iter`: 1000 (Convergence garantisi)
- `class_weight`: 'balanced' (SÄ±nÄ±f dengesizliÄŸi iÃ§in ek koruma)
- `random_state`: 42

**4.3.2 Random Forest Classifier**

Ensemble (topluluk) Ã¶ÄŸrenme mantÄ±ÄŸÄ±yla Ã§alÄ±ÅŸan bu model, verideki aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting) riskine karÅŸÄ± dayanÄ±klÄ± yapÄ±sÄ± ve deÄŸiÅŸkenler arasÄ±ndaki doÄŸrusal olmayan iliÅŸkileri yakalayabilme yeteneÄŸi nedeniyle tercih edilmiÅŸtir. AyrÄ±ca klinik iÃ§gÃ¶rÃ¼ler elde etmek adÄ±na kritik Ã¶neme sahip olan Ã¶zellik Ã¶nem analizini (feature importance) baÅŸarÄ±yla gerÃ§ekleÅŸtirmektedir.

**Hiperparametreler:**
- `n_estimators`: 100 (100 karar aÄŸacÄ±)
- `max_depth`: 10 (Overfitting'i Ã¶nlemek iÃ§in)
- `min_samples_split`: 10
- `min_samples_leaf`: 4
- `class_weight`: 'balanced'
- `n_jobs`: -1 (TÃ¼m CPU'lar kullanÄ±lÄ±r)

**4.3.3 XGBoost (Extreme Gradient Boosting)**

Modern makine Ã¶ÄŸrenmesi Ã§alÄ±ÅŸmalarÄ±nda yÃ¼ksek baÅŸarÄ± oranlarÄ±yla bilinen bu algoritma, dÃ¼zenlileÅŸtirme (regularization) teknikleri sayesinde modelin genelleme yeteneÄŸini maksimize etmek iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r. KarmaÅŸÄ±k veri yapÄ±larÄ±nda hÄ±zlÄ± ve etkili sonuÃ§lar Ã¼retmesi, bu projenin tahmin gÃ¼cÃ¼nÃ¼ artÄ±rmada stratejik bir rol oynamaktadÄ±r.

**Hiperparametreler:**
- `n_estimators`: 100
- `max_depth`: 6
- `learning_rate`: 0.1
- `subsample`: 0.8 (Row subsampling)
- `colsample_bytree`: 0.8 (Column subsampling)
- `eval_metric`: 'logloss'

**4.3.4 LightGBM (Light Gradient Boosting Machine)**

BÃ¼yÃ¼k veri setlerinde diÄŸer boosting yÃ¶ntemlerine gÃ¶re Ã§ok daha hÄ±zlÄ± eÄŸitim sÃ¼resi ve dÃ¼ÅŸÃ¼k bellek kullanÄ±mÄ± sunmasÄ± nedeniyle seÃ§ilmiÅŸtir. Yaprak odaklÄ± (leaf-wise) bÃ¼yÃ¼me stratejisi sayesinde karmaÅŸÄ±k Ã¶rÃ¼ntÃ¼leri daha derinlemesine analiz edebilme kabiliyetine sahiptir.

**Hiperparametreler:**
- `n_estimators`: 100
- `max_depth`: 6
- `learning_rate`: 0.1
- `subsample`: 0.8
- `colsample_bytree`: 0.8
- `class_weight`: 'balanced'

**4.3.5 Support Vector Machine (SVM)**

Kernel yÃ¶ntemlerini kullanarak yÃ¼ksek boyutlu veri uzaylarÄ±nda etkili karar sÄ±nÄ±rlarÄ± oluÅŸturabilme yeteneÄŸi nedeniyle karÅŸÄ±laÅŸtÄ±rma grubuna dahil edilmiÅŸtir. Teorik aÃ§Ä±dan gÃ¼Ã§lÃ¼ bir sÄ±nÄ±flandÄ±rÄ±cÄ± olmasÄ±, verinin farklÄ± geometrik temsilleri Ã¼zerinden risk tahmininde bulunulmasÄ±na imkÃ¢n saÄŸlamaktadÄ±r.

**Hiperparametreler:**
- `kernel`: 'rbf' (Radial Basis Function)
- `C`: 1.0 (Regularization parameter)
- `gamma`: 'scale'
- `class_weight`: 'balanced'
- `probability`: True (ROC curve iÃ§in gerekli)

### 4.4 Cross-Validation Stratejisi

Model performanslarÄ±nÄ±n gÃ¼venilir bir ÅŸekilde deÄŸerlendirilmesi iÃ§in **5-Fold Stratified Cross-Validation** uygulanmÄ±ÅŸtÄ±r.

**4.4.1 YÃ¶ntem AÃ§Ä±klamasÄ±**

1. **Stratified K-Fold:** Veri 5 eÅŸit parÃ§aya bÃ¶lÃ¼nÃ¼r, her parÃ§ada sÄ±nÄ±f oranlarÄ± korunur
2. **Her iterasyonda:** 4 parÃ§a eÄŸitim, 1 parÃ§a validasyon iÃ§in kullanÄ±lÄ±r
3. **5 iterasyon sonunda:** Ortalama ve standart sapma hesaplanÄ±r

**4.4.2 DeÄŸerlendirme Metrikleri**

- **Accuracy:** Genel doÄŸruluk oranÄ±
- **ROC-AUC:** Discriminative power (ayÄ±rt etme gÃ¼cÃ¼)

**4.4.3 Cross-Validation SonuÃ§larÄ±**

| Model | CV Accuracy (Mean Â± Std) | CV ROC-AUC (Mean Â± Std) |
|-------|--------------------------|-------------------------|
| **Logistic Regression** | 0.6120 Â± 0.0042 | 0.6518 Â± 0.0062 |
| **Random Forest** | 0.8122 Â± 0.0059 | 0.8837 Â± 0.0036 |
| **XGBoost** | 0.8834 Â± 0.0016 | 0.9149 Â± 0.0009 |
| **LightGBM** | 0.8855 Â± 0.0013 | 0.9159 Â± 0.0014 |
| **SVM** | 0.7056 Â± 0.0071 | 0.7800 Â± 0.0054 |

**GÃ¶zlemler:**

1. **En YÃ¼ksek CV Accuracy:** LightGBM (0.8855)
2. **En YÃ¼ksek CV ROC-AUC:** LightGBM (0.9159)
3. **En DÃ¼ÅŸÃ¼k Varyans:** XGBoost ve LightGBM (std < 0.002)
4. **Baseline:** Logistic Regression (0.6120 accuracy)

Gradient boosting modelleri (XGBoost, LightGBM) cross-validation'da belirgin Ã¼stÃ¼nlÃ¼k gÃ¶stermiÅŸtir.

### 4.5 Model EÄŸitim SÃ¼reci ve Performans Metrikleri

Her model, resampled train set ile eÄŸitilmiÅŸ ve hem train hem de test setlerinde deÄŸerlendirilmiÅŸtir.

**4.5.1 Test Set Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±**

| Model | Accuracy | Precision | Recall | F1-Score | ROC-AUC | EÄŸitim SÃ¼resi |
|-------|----------|-----------|--------|----------|---------|---------------|
| **Logistic Regression** | 0.6373 | 0.1676 | 0.5672 | 0.2587 | 0.6530 | 2.73s |
| **Random Forest** | 0.7989 | 0.2076 | 0.2849 | 0.2402 | 0.6507 | 5.85s |
| **XGBoost** | 0.8862 | 0.4096 | 0.0449 | 0.0810 | 0.6674 | 2.72s |
| **LightGBM** | 0.8851 | 0.4086 | 0.0669 | 0.1150 | 0.6743 | 6.47s |
| **SVM** | 0.6693 | 0.1660 | 0.4883 | 0.2478 | 0.6246 | 6896.93s |

![Model Comparison Metrics](docs/model_training/02_model_comparison_metrics.png)
*Åekil 4.5: Modellerin test set'teki performans metriklerinin karÅŸÄ±laÅŸtÄ±rmasÄ±*


**4.5.2 Metrik BazlÄ± Analizler**

**Accuracy (DoÄŸruluk OranÄ±):** En yÃ¼ksek deÄŸer %88,62 ile XGBoost modelinde gÃ¶rÃ¼lÃ¼rken, en dÃ¼ÅŸÃ¼k deÄŸer %63,73 ile Lojistik Regresyon modelinde saptanmÄ±ÅŸtÄ±r. Ancak veri setindeki belirgin sÄ±nÄ±f dengesizliÄŸi nedeniyle, XGBoost ve LightGBM modellerinin sunduÄŸu yÃ¼ksek doÄŸruluk oranlarÄ±nÄ±n yanÄ±ltÄ±cÄ± olabileceÄŸi deÄŸerlendirilmektedir.

**Precision (Kesinlik):** XGBoost %40,96 ile **"tekrar yatÄ±ÅŸ"** tahminlerinde en yÃ¼ksek kesinliÄŸi saÄŸlarken, SVM %16,60 oranÄ±yla bu alanda en dÃ¼ÅŸÃ¼k performansÄ± sergilemiÅŸtir. Bu metrik, modellerin pozitif olarak sÄ±nÄ±flandÄ±rdÄ±ÄŸÄ± vakalarÄ±n ne kadarÄ±nÄ±n gerÃ§ek klinik karÅŸÄ±lÄ±ÄŸÄ± olduÄŸunu Ã¶lÃ§erek "yanlÄ±ÅŸ alarm" oranÄ±nÄ± belirlemektedir.

**Recall (DuyarlÄ±lÄ±k - Sensitivity):** Klinik aÃ§Ä±dan en kritik parametre olan duyarlÄ±lÄ±kta, Lojistik Regresyon %56,72 ile en yÃ¼ksek baÅŸarÄ±yÄ± gÃ¶sterirken XGBoost %04,49 ile en zayÄ±f sonucu Ã¼retmiÅŸtir. Bu sonuÃ§lar, Lojistik Regresyon'un gerÃ§ek riskli hastalarÄ± tespit etme gÃ¼cÃ¼nÃ¼n diÄŸer modellere gÃ¶re Ã§ok daha yÃ¼ksek olduÄŸunu kanÄ±tlamaktadÄ±r.

**F1-Score (Precision-Recall Dengesi):** Kesinlik ve duyarlÄ±lÄ±k deÄŸerlerinin harmonik ortalamasÄ±nÄ± temsil eden F1-Skorunda, Lojistik Regresyon 0,2587 ile en dengeli performansÄ± sergilemiÅŸtir. Buna karÅŸÄ±n XGBoost, Ã¶zellikle dÃ¼ÅŸÃ¼k duyarlÄ±lÄ±k oranÄ±nÄ±n etkisiyle 0,0810 seviyesinde kalarak en dÃ¼ÅŸÃ¼k denge skorunu almÄ±ÅŸtÄ±r.

**ROC-AUC (Discriminative Power):** Modellerin sÄ±nÄ±flarÄ± birbirinden ayÄ±rt etme yeteneÄŸini gÃ¶steren bu Ã¶lÃ§ekte LightGBM 0,6743 ile en iyi performansÄ± gÃ¶sterirken, SVM 0,6246 ile en sonda yer almÄ±ÅŸtÄ±r. Genel tabloda tÃ¼m modellerin 0,60-0,68 aralÄ±ÄŸÄ±nda kalmasÄ±, problemin doÄŸasÄ± gereÄŸi modellerin orta seviyede bir ayÄ±rt etme gÃ¼cÃ¼ne sahip olduÄŸunu gÃ¶stermektedir.

**Training Time (EÄŸitim SÃ¼resi):** XGBoost 2,72 saniyelik eÄŸitim sÃ¼resiyle operasyonel aÃ§Ä±dan en hÄ±zlÄ± model olurken, SVM yaklaÅŸÄ±k 1,9 saatlik (6896,93s) sÃ¼resiyle en yavaÅŸ model olarak kaydedilmiÅŸtir. SVM modelinin sergilediÄŸi bu aÅŸÄ±rÄ± gecikme, kullanÄ±lan RBF Ã§ekirdeÄŸinin (kernel) hesaplama maliyetinin yÃ¼ksekliÄŸinden kaynaklanmaktadÄ±r.

**4.5.3 Ã–nemli Bulgular ve Yorumlar**

**1. DoÄŸruluk ve DuyarlÄ±lÄ±k Dengesi (Accuracy vs. Recall Trade-off):**

XGBoost ve LightGBM modelleri genel doÄŸruluk oranÄ±nda yÃ¼ksek baÅŸarÄ± sergilese de, klinik aÃ§Ä±dan kritik olan pozitif sÄ±nÄ±fÄ± (SÄ±nÄ±f 1) tespit etmede yetersiz kalarak dÃ¼ÅŸÃ¼k duyarlÄ±lÄ±k deÄŸerleri Ã¼retmiÅŸtir. Buna karÅŸÄ±n Lojistik Regresyon, en dÃ¼ÅŸÃ¼k genel doÄŸruluÄŸa sahip olmasÄ±na raÄŸmen en yÃ¼ksek duyarlÄ±lÄ±k oranÄ±na ulaÅŸarak riskli hastalarÄ±n yakalanmasÄ±nda en etkili model olmuÅŸtur.

**2. Klinik Perspektif ve Hata Analizi**

Hastaneye tekrar yatÄ±ÅŸ tahminlerinde, riskli bir hastanÄ±n gÃ¶zden kaÃ§Ä±rÄ±lmasÄ± anlamÄ±na gelen "HatalÄ± Negatif" (False Negative) sonuÃ§lar, en yÃ¼ksek maliyetli ve hayati risk taÅŸÄ±yan hata tipi olarak deÄŸerlendirilmektedir. Bu nedenle, daha fazla "yanlÄ±ÅŸ alarm" Ã¼retilse dahi (dÃ¼ÅŸÃ¼k kesinlik), kritik hastalarÄ± kaÃ§Ä±rmamak adÄ±na yÃ¼ksek duyarlÄ±lÄ±k deÄŸerine sahip modellerin tercih edilmesi klinik Ã¶nceliklerle Ã¶rtÃ¼ÅŸmektedir.

**3. AyÄ±rt Etme GÃ¼cÃ¼ (ROC-AUC) Analizi**

TÃ¼m modellerin ROC-AUC deÄŸerlerinin 0,62 ile 0,67 gibi orta bir aralÄ±kta kÃ¼melenmesi, algoritmalarÄ±n sÄ±nÄ±flarÄ± birbirinden ayÄ±rt etme gÃ¼cÃ¼nÃ¼n belirli bir sÄ±nÄ±rda kaldÄ±ÄŸÄ±nÄ± gÃ¶stermektedir. Bu durum, veri setinin doÄŸasÄ±ndan kaynaklanan karmaÅŸÄ±klÄ±ÄŸÄ±n ve sÄ±nÄ±f dengesizliÄŸinin, tahmin sÃ¼recini tÃ¼m modeller iÃ§in zorlaÅŸtÄ±ran temel unsur olduÄŸunu kanÄ±tlamaktadÄ±r.

**4. Hesaplama VerimliliÄŸi (Computational Efficiency)**

Destek VektÃ¶r Makineleri (SVM) modelinin sergilediÄŸi aÅŸÄ±rÄ± uzun eÄŸitim sÃ¼resi, bu algoritmanÄ±n gerÃ§ek zamanlÄ± klinik uygulamalar ve bÃ¼yÃ¼k Ã¶lÃ§ekli veri setleri iÃ§in pratik bir seÃ§enek olmadÄ±ÄŸÄ±nÄ± ortaya koymuÅŸtur. Lojistik Regresyon, XGBoost ve LightGBM ise hÄ±zlÄ± iÅŸlem sÃ¼releriyle operasyonel verimlilik aÃ§Ä±sÄ±ndan Ã§ok daha uygulanabilir alternatifler olarak Ã¶ne Ã§Ä±kmaktadÄ±r.

### 4.6 ROC EÄŸrisi Analizi

ROC (Receiver Operating Characteristic) eÄŸrisi, farklÄ± classification threshold'larÄ±nda modelin True Positive Rate (TPR) ve False Positive Rate (FPR) iliÅŸkisini gÃ¶rselleÅŸtirir.

**4.6.1 ROC EÄŸrisi**

- **Perfect Classifier:** AUC = 1.0 (Sol Ã¼st kÃ¶ÅŸeden geÃ§er)
- **Random Classifier:** AUC = 0.5 (45Â° diagonal Ã§izgi)
- **Worse than Random:** AUC < 0.5

**ROC-AUC DeÄŸerlendirme SkalasÄ±:**
- 0.90-1.00: MÃ¼kemmel
- 0.80-0.90: Ã‡ok iyi
- 0.70-0.80: Ä°yi
- 0.60-0.70: Orta â¬… **modellerim**
- 0.50-0.60: ZayÄ±f

![ROC Curves](docs/model_training/03_roc_curves.png)
*Åekil 4.3: TÃ¼m modellerin ROC eÄŸrileri ve AUC deÄŸerleri karÅŸÄ±laÅŸtÄ±rmasÄ±*

**4.6.2 Model BazlÄ± ROC Analizi**

1. **LightGBM (AUC=0.6743):** En iyi discriminative power
2. **XGBoost (AUC=0.6674):** Ä°kinci sÄ±rada, LightGBM'e yakÄ±n
3. **Logistic Regression (AUC=0.6530):** Baseline modelden biraz daha iyi
4. **Random Forest (AUC=0.6507):** Orta seviye
5. **SVM (AUC=0.6246):** En dÃ¼ÅŸÃ¼k, random'a yakÄ±n

**4.6.3 Threshold SeÃ§imi**

ROC eÄŸrisi, optimal threshold seÃ§imi iÃ§in kullanÄ±labilir:
- **YÃ¼ksek Recall Ä°stiyorsak:** Threshold'u dÃ¼ÅŸÃ¼rÃ¼rÃ¼z (daha fazla pozitif tahmin)
- **YÃ¼ksek Precision Ä°stiyorsak:** Threshold'u yÃ¼kselttiriz (daha az pozitif tahmin)
- **Klinik Karar:** Recall'u Ã¶nceliklendirmek mantÄ±klÄ± (hastalarÄ± kaÃ§Ä±rmamak iÃ§in)

### 4.7 Confusion Matrix Analizi

Confusion matrix, modelin tahminlerinin detaylÄ± dÃ¶kÃ¼mÃ¼nÃ¼ saÄŸlar.

**Confusion Matrix BileÅŸenleri:**

|  | Tahmin: Negatif | Tahmin: Pozitif |
|--|----------------|-----------------|
| **GerÃ§ek: Negatif** | TN (True Negative) | FP (False Positive) |
| **GerÃ§ek: Pozitif** | FN (False Negative) | TP (True Positive) |

![Confusion Matrices](docs/model_training/04_confusion_matrices.png)
*Åekil 4.4: TÃ¼m modellerin confusion matrix gÃ¶rselleÅŸtirmeleri*

**4.7.1 Model KarÅŸÄ±laÅŸtÄ±rmasÄ± (Confusion Matrix BazlÄ±)**

**Logistic Regression:**
- TP: 1288, FN: 983 (Recall = 0.567)
- En yÃ¼ksek recall, en az hasta kaÃ§Ä±rÄ±yor
- Ancak FP sayÄ±sÄ± yÃ¼ksek (6299)

**XGBoost:**
- TP: 102, FN: 2169 (Recall = 0.045)
- Ã‡ok yÃ¼ksek FN, kritik hastalarÄ±n %95.5'ini kaÃ§Ä±rÄ±yor
- YÃ¼ksek accuracy aldatÄ±cÄ±, klinik kullanÄ±m iÃ§in uygun deÄŸil

**LightGBM:**
- TP: 152, FN: 2119 (Recall = 0.067)
- XGBoost'tan biraz daha iyi ama hala Ã§ok dÃ¼ÅŸÃ¼k recall

### 4.8 Model EÄŸitimi SonuÃ§larÄ± ve DeÄŸerlendirme

**4.8.1 Genel DeÄŸerlendirme**

5 farklÄ± makine Ã¶ÄŸrenmesi modeli baÅŸarÄ±yla eÄŸitilmiÅŸ ve test edilmiÅŸtir. Her modelin farklÄ± gÃ¼Ã§lÃ¼ ve zayÄ±f yÃ¶nleri olduÄŸu tespit edilmiÅŸtir.

**Model Performans Ã–zeti:**

| Kriter | En Ä°yi Model | DeÄŸer | Yorum |
|--------|--------------|-------|-------|
| **CV Accuracy** | LightGBM | 0.8855 | EÄŸitim seti performansÄ± |
| **CV ROC-AUC** | LightGBM | 0.9159 | EÄŸitim seti discrimination |
| **Test Accuracy** | XGBoost | 0.8862 | Genel doÄŸruluk |
| **Test Recall** | Logistic Regression | 0.5672 | Kritik hasta tespiti |
| **Test F1-Score** | Logistic Regression | 0.2587 | Dengeli metrik |
| **Test ROC-AUC** | LightGBM | 0.6743 | Test set discrimination |
| **Training Speed** | XGBoost | 2.72s | HÄ±z |

**4.8.2 Kritik Bulgular**

**1. Ã‡apraz DoÄŸrulama ve Test PerformansÄ± ArasÄ±ndaki Sapma:** XGBoost ve LightGBM modellerinde Ã‡apraz DoÄŸrulama (CV) aÅŸamasÄ±nda gÃ¶zlemlenen yÃ¼ksek ROC-AUC deÄŸerlerinin (0.91+), test setinde 0.67 seviyesine gerilemesi Ã¶nemli bir performans sapmasÄ±na iÅŸaret etmektedir. Bu durum, modellerin yeniden Ã¶rneklenmiÅŸ (resampled) eÄŸitim verisine aÅŸÄ±rÄ± uyum saÄŸladÄ±ÄŸÄ±nÄ± ve orijinal dengesiz daÄŸÄ±lÄ±ma sahip test verisinde genelleme yeteneÄŸinin dÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ kanÄ±tlamaktadÄ±r.

**2. DuyarlÄ±lÄ±k (Recall) Sorunu ve Klinik YansÄ±malarÄ±:** XGBoost ve LightGBM gibi geliÅŸmiÅŸ boosting modellerinin %4 ile %6 arasÄ±nda seyreden Ã§ok dÃ¼ÅŸÃ¼k duyarlÄ±lÄ±k oranlarÄ± Ã¼retmesi, klinik uygulama aÃ§Ä±sÄ±ndan kabul edilemez dÃ¼zeyde yÃ¼ksek bir hatalÄ± negatif (FN) oranÄ±na yol aÃ§maktadÄ±r. Bu kÄ±sÄ±tÄ±n aÅŸÄ±lmasÄ± ve riskli hastalarÄ±n gÃ¶zden kaÃ§Ä±rÄ±lmamasÄ± iÃ§in karar eÅŸiÄŸi optimizasyonu (threshold tuning) sÃ¼reÃ§lerinin uygulanmasÄ± bir zorunluluk olarak gÃ¶rÃ¼lmektedir.

**3. Lojistik Regresyon Modelinin Beklenmeyen BaÅŸarÄ±sÄ±:** Daha basit bir mimariye sahip olmasÄ±na raÄŸmen Lojistik Regresyon, tÃ¼m modeller arasÄ±nda en yÃ¼ksek duyarlÄ±lÄ±k deÄŸerini ve en iyi F1 skorunu Ã¼reterek dikkat Ã§ekici bir performans sergilemiÅŸtir. Modelin sergilediÄŸi bu kararlÄ± yapÄ± ve kritik vakalarÄ± yakalama gÃ¼cÃ¼, gerÃ§ek dÃ¼nya klinik uygulamalarÄ±nda ve canlÄ± sistem daÄŸÄ±tÄ±mlarÄ±nda (deployment) diÄŸer karmaÅŸÄ±k modellere gÃ¶re daha uygun bir seÃ§enek olduÄŸunu ortaya koymaktadÄ±r.

**4. SÄ±nÄ±f DengesizliÄŸi ile MÃ¼cadeledeki Zorluklar:** EÄŸitim aÅŸamasÄ±nda SMOTE tekniÄŸi uygulanmasÄ±na raÄŸmen, modellerin test setinde Ã§oÄŸunluk sÄ±nÄ±fÄ±na karÅŸÄ± olan eÄŸilimlerinin (bias) devam ettiÄŸi ve azÄ±nlÄ±k sÄ±nÄ±fÄ±nÄ± tahmin etmekte zorlandÄ±ÄŸÄ± saptanmÄ±ÅŸtÄ±r. Bu sorunun Ã§Ã¶zÃ¼mÃ¼ iÃ§in gelecekteki Ã§alÄ±ÅŸmalarda daha agresif sÄ±nÄ±f aÄŸÄ±rlÄ±klandÄ±rma yÃ¶ntemlerinin veya maliyete duyarlÄ± Ã¶ÄŸrenme stratejilerinin kullanÄ±lmasÄ± Ã¶nerilmektedir.

## 5. MODEL DEÄERLENDÄ°RME

Model eÄŸitim aÅŸamasÄ± tamamlandÄ±ktan sonra, modellerin performanslarÄ± detaylÄ± olarak analiz edilmiÅŸtir. Bu bÃ¶lÃ¼mde precision-recall analizi, threshold optimizasyonu, model kalibrasyonu, feature importance ve error analizi gibi ileri seviye deÄŸerlendirme teknikleri uygulanmÄ±ÅŸtÄ±r.

### 5.1 Precision-Recall Analizi

**5.1.1 Precision-Recall vs ROC Curve**

Dengesiz veri setlerinde (imbalanced datasets), ROC eÄŸrisi yanÄ±ltÄ±cÄ± olabilir Ã§Ã¼nkÃ¼ True Negative (TN) sayÄ±sÄ± Ã§ok yÃ¼ksektir ve bu FPR'yi dÃ¼ÅŸÃ¼k gÃ¶sterir. Precision-Recall eÄŸrisi, azÄ±nlÄ±k sÄ±nÄ±fÄ±na (pozitif sÄ±nÄ±f) odaklandÄ±ÄŸÄ± iÃ§in bu problemde daha informatif bir metriktir.

**Neden Precision-Recall?**
- **Precision:** Pozitif tahminlerin doÄŸruluÄŸu (FP'leri penalize eder)
- **Recall:** Pozitif Ã¶rnekleri yakalama gÃ¼cÃ¼ (FN'leri penalize eder)
- Dengesiz veride her iki metrik de kritik

**5.1.2 Average Precision (AP) SonuÃ§larÄ±**

Average Precision, precision-recall curve altÄ±ndaki alanÄ± temsil eder ve tÃ¼m threshold deÄŸerlerinde modelin performansÄ±nÄ± Ã¶zetler.

| Model | Average Precision | Yorumlama |
|-------|-------------------|-----------|
| **LightGBM** | 0.2235 | En yÃ¼ksek AP |
| **XGBoost** | 0.2178 | Ä°kinci sÄ±rada |
| **Logistic Regression** | 0.1981 | Baseline'Ä±n Ã¼stÃ¼nde |
| **Random Forest** | 0.1889 | Orta seviye |
| **SVM** | 0.1699 | En dÃ¼ÅŸÃ¼k |

**Genel DeÄŸerlendirme:**
- TÃ¼m modellerin AP deÄŸerleri 0.17-0.22 aralÄ±ÄŸÄ±nda (dÃ¼ÅŸÃ¼k-orta)
- Bu, problemin doÄŸasÄ± gereÄŸi tahmin zorluÄŸunu gÃ¶steriyor
- AzÄ±nlÄ±k sÄ±nÄ±fÄ± (11.16%) iÃ§in precision-recall dengesi zor

![Precision-Recall Curves](docs/model_evaluation/01_precision_recall_curves.png)
*Åekil 5.1: TÃ¼m modellerin Precision-Recall eÄŸrileri ve Average Precision deÄŸerleri*

### 5.2 Threshold Optimizasyonu

**5.2.1 Threshold KavramÄ±**

SÄ±nÄ±flandÄ±rma modellerinde default threshold genellikle 0.5'tir:
- EÄŸer P(readmission) â‰¥ 0.5 â†’ Tahmin = 1 (Readmission)
- EÄŸer P(readmission) < 0.5 â†’ Tahmin = 0 (No readmission)

Ancak bu threshold her problem iÃ§in optimal deÄŸildir. Ã–zellikle:
- Dengesiz veri setlerinde
- FarklÄ± hata tiplerinin farklÄ± maliyetleri olduÄŸunda
- Belirli bir metriÄŸi optimize etmek istediÄŸimizde

threshold'u deÄŸiÅŸtirerek precision-recall trade-off'unu ayarlayabiliriz.

**5.2.2 Optimal Threshold Bulma Stratejileri**

Ä°ki farklÄ± optimizasyon kriteri kullanÄ±lmÄ±ÅŸtÄ±r:

**1. F1-Optimal Threshold:**
- F1-score'u (precision ve recall'un harmonik ortalamasÄ±) maksimize eder
- Dengeli performans iÃ§in kullanÄ±lÄ±r

**2. Youden's J-Optimal Threshold:**
- J = Sensitivity + Specificity - 1 formÃ¼lÃ¼nÃ¼ maksimize eder
- ROC curve'den tÃ¼retilir
- Genel discriminative power iÃ§in kullanÄ±lÄ±r

**5.2.3 Optimal Threshold SonuÃ§larÄ±**

| Model | F1-Optimal Threshold | F1-Score | J-Optimal Threshold | J-Score |
|-------|---------------------|----------|---------------------|---------|
| **Logistic Regression** | 0.500 | 0.2587 | 0.455 | 0.2250 |
| **Random Forest** | 0.450 | 0.2636 | 0.397 | 0.2230 |
| **XGBoost** | 0.200 | 0.2715 | 0.209 | 0.2504 |
| **LightGBM** | 0.300 | 0.2788 | 0.240 | 0.2527 |
| **SVM** | 0.350 | 0.2488 | 0.313 | 0.1994 |


<div style="
    border-left: 5px solid #FF9800;
    background-color: #FFF3E0;
    padding: 10px;
    margin: 10px 0;
">
<strong>ğŸ¦‰ GÃ¶zlemler</strong><br>

1. **Boosting Modelleri DÃ¼ÅŸÃ¼k Threshold Ä°ster:**
   - XGBoost: 0.200, LightGBM: 0.300
   - Bu modeller Ã§ok confident tahminler yapÄ±yor (overconfident)
   - Threshold dÃ¼ÅŸÃ¼rÃ¼ldÃ¼ÄŸÃ¼nde F1-score arttÄ± (0.08 â†’ 0.27)

2. **Linear Model KararlÄ±:**
   - Logistic Regression: 0.500 (default optimal)
   - Model iyi kalibre edilmiÅŸ

3. **F1-Score Ä°yileÅŸtirme:**
   - LightGBM threshold 0.5 â†’ 0.3: F1 0.115 â†’ 0.279 (+%142)
   - XGBoost threshold 0.5 â†’ 0.2: F1 0.081 â†’ 0.271 (+%235)
</div>

### 5.3 Model Kalibrasyonu Analizi

**5.3.1 Kalibrasyon KavramÄ± ve GÃ¼venilirlik Analizi**

Model kalibrasyonu, bir sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±n Ã¼rettiÄŸi olasÄ±lÄ±k tahminlerinin gerÃ§ek dÃ¼nya sonuÃ§larÄ±yla ne Ã¶lÃ§Ã¼de Ã¶rtÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ ve istatistiksel olarak ne kadar gÃ¼venilir olduÄŸunu deÄŸerlendirmektedir. Ä°deal ÅŸekilde kalibre edilmiÅŸ bir modelde, tahmin edilen olasÄ±lÄ±klarÄ±n gerÃ§ekleÅŸme oranlarÄ±yla birebir eÅŸleÅŸmesi beklenir; Ã¶rneÄŸin, %30 tekrar yatÄ±ÅŸ olasÄ±lÄ±ÄŸÄ± atanan 100 hastadan yaklaÅŸÄ±k 30'unun gerÃ§ekte hastaneye geri dÃ¶nmesi modelin tutarlÄ±lÄ±ÄŸÄ±nÄ± kanÄ±tlamaktadÄ±r. Bu durumun gÃ¶rsel bir gÃ¶stergesi olan kalibrasyon eÄŸrisinin (calibration curve), ideal referans noktasÄ± kabul edilen 45 derecelik diyagonal Ã§izgiye yakÄ±nlÄ±ÄŸÄ± modelin gÃ¼venilirliÄŸini belirlemektedir.

Kalibrasyon sÃ¼recinde karÅŸÄ±laÅŸÄ±lan temel sapmalar iki ana grupta incelenmektedir:

- **AÅŸÄ±rÄ± GÃ¼venli (Overconfident) Tahminler:** Modelin gerÃ§ek olasÄ±lÄ±ktan daha yÃ¼ksek deÄŸerler atamasÄ± durumudur; bu senaryoda kalibrasyon eÄŸrisi diyagonal Ã§izginin altÄ±nda kalmakta ve modelin riskleri olduÄŸundan daha bÃ¼yÃ¼k gÃ¶stermesine neden olmaktadÄ±r.

- **Yetersiz GÃ¼venli (Underconfident) Tahminler:** Modelin gerÃ§ek risk oranlarÄ±nÄ± yansÄ±tmakta zayÄ±f kalarak daha dÃ¼ÅŸÃ¼k olasÄ±lÄ±klar Ã¼retmesidir; bu durumda eÄŸri diyagonalin Ã¼zerinde seyretmekte, bu da gerÃ§ek risklerin gÃ¶zden kaÃ§Ä±rÄ±lmasÄ±na yol aÃ§abilmektedir.

**5.3.2 Kalibrasyon SonuÃ§larÄ±**

![Calibration Curves](docs/model_evaluation/03_calibration_curves.png)
*Åekil 5.3: Model kalibrasyon eÄŸrileri - tahmin edilen vs. gÃ¶zlenen olasÄ±lÄ±klar*

### 5.4 Ã–zellik Ã–nemi Analizi

Ã–zellik Ã¶nemi (`feature importance`), modellerin hangi Ã¶zellikleri ne kadar Ã¶nemli bulduÄŸunu gÃ¶sterir. Bu analiz hem model yorumlanabilirliÄŸi hem de klinik iÃ§gÃ¶rÃ¼ler aÃ§Ä±sÄ±ndan kritiktir.

**5.4.1 AÄŸaÃ§ TabanlÄ± Modeller iÃ§in Ã–zellik SeÃ§imi**

Random Forest, XGBoost ve LightGBM iÃ§in Gini importance (veya gain) kullanÄ±larak feature importance hesaplanmÄ±ÅŸtÄ±r.

![Feature Importance](docs/model_evaluation/04_feature_importance.png)
*Åekil 5.4.1: Tree-based modellerde en Ã¶nemli 20 Ã¶zellik*

**Ortak En Ã–nemli Ã–zellikler (TÃ¼m Tree Models):**

| SÄ±ra | Ã–zellik | Klinik AnlamÄ± |
|------|---------|---------------|
| 1 | `number_inpatient` | GeÃ§miÅŸ hastaneye yatÄ±ÅŸ sayÄ±sÄ± |
| 2 | `number_emergency` | Acil servis baÅŸvuru sayÄ±sÄ± |
| 3 | `time_in_hospital` | Bu yatÄ±ÅŸta hastanede kalma sÃ¼resi |
| 4 | `discharge_disposition_id` | Taburcu durumu/yeri |
| 5 | `number_diagnoses` | Toplam teÅŸhis sayÄ±sÄ± |
| 6 | `num_medications` | KullanÄ±lan ilaÃ§ sayÄ±sÄ± |
| 7 | `num_lab_procedures` | YapÄ±lan laboratuvar testi sayÄ±sÄ± |
| 8 | `age_numeric` | Hasta yaÅŸÄ± |
| 9 | `diag_1_freq` | Birincil teÅŸhis sÄ±klÄ±ÄŸÄ± |
| 10 | `admission_type_id` | Kabul tipi |

**Ã–zelliklerin Klinik YorumlanmasÄ± ve Risk DeÄŸerlendirmesi**

- **SaÄŸlÄ±k Hizmeti KullanÄ±m GeÃ§miÅŸinin Kritik Ã–nemi:** YapÄ±lan analizler sonucunda, `number_inpatient` (geÃ§miÅŸ yatarak tedavi sayÄ±sÄ±) ve `number_emergency` (acil servis baÅŸvuru sayÄ±sÄ±) deÄŸiÅŸkenlerinin modelin en gÃ¼Ã§lÃ¼ tahmin edicileri olduÄŸu saptanmÄ±ÅŸtÄ±r. Bu durum, kronik hastalÄ±k yÃ¶netiminde geÃ§miÅŸ baÅŸvurularÄ±n gelecekteki tekrar yatÄ±ÅŸ riskleri iÃ§in en belirgin gÃ¶sterge olduÄŸunu ve saÄŸlÄ±k hizmeti kullanÄ±m geÃ§miÅŸinin (healthcare utilization history) ana risk faktÃ¶rÃ¼ olarak deÄŸerlendirilmesi gerektiÄŸini ortaya koymaktadÄ±r.

- **Hastanede KalÄ±ÅŸ SÃ¼resi ve Taburcu Durumu Etkisi:** `time_in_hospital` deÄŸiÅŸkeni, yÃ¼ksek Ã¶nem derecesine sahip olsa da karmaÅŸÄ±k bir iliÅŸki sergilemektedir; uzun yatÄ±ÅŸ sÃ¼releri vaka karmaÅŸÄ±klÄ±ÄŸÄ±na iÅŸaret ederken, Ã§ok kÄ±sa sÃ¼reli yatÄ±ÅŸlar ise yetersiz tedavi (under-treatment) riski nedeniyle tekrar yatÄ±ÅŸ olasÄ±lÄ±ÄŸÄ±nÄ± artÄ±rabilmektedir. Benzer ÅŸekilde, `discharge_disposition_id` Ã¶zniteliÄŸi, hastanÄ±n taburcu edildikten sonra eve mi yoksa bir rehabilitasyon merkezine mi sevk edildiÄŸinin, iyileÅŸme sÃ¼recindeki takip kalitesi ve dolayÄ±sÄ±yla risk seviyesi Ã¼zerinde doÄŸrudan belirleyici olduÄŸunu gÃ¶stermektedir.

- **HastalÄ±k KarmaÅŸÄ±klÄ±ÄŸÄ± ve Polifarmasi FaktÃ¶rÃ¼:** Modelde yÃ¼ksek Ã¶nem arz eden number_diagnoses ve num_medications deÄŸiÅŸkenleri, hastanÄ±n komorbidite (eÅŸlik eden hastalÄ±k) yÃ¼kÃ¼nÃ¼ ve ilaÃ§ kullanÄ±m yoÄŸunluÄŸunu yansÄ±tmaktadÄ±r. Ã‡oklu morbidite durumu genel klinik riski yÃ¼kseltirken; polifarmasi (Ã§oklu ilaÃ§ kullanÄ±mÄ±), hasta uyumu (compliance) sorunlarÄ± ve ilaÃ§ etkileÅŸimleri nedeniyle tekrar yatÄ±ÅŸ tetikleyicisi olarak Ã¶ne Ã§Ä±kmaktadÄ±r.

**5.4.2 Lojistik Regresyon KatsayÄ± Analizi**

Lojistik Regresyon, doÄŸrusal bir model mimarisine sahip olmasÄ± nedeniyle katsayÄ±larÄ±n (coefficients) doÄŸrudan yorumlanmasÄ±na imkan tanÄ±yarak klinik ÅŸeffaflÄ±k saÄŸlamaktadÄ±r. Bu modelde her bir katsayÄ±, ilgili Ã¶znitelikteki bir birimlik deÄŸiÅŸimin, hastanÄ±n tekrar yatÄ±ÅŸ olasÄ±lÄ±ÄŸÄ±nÄ±n log-oranÄ± (log-odds) Ã¼zerindeki etkisini ifade etmekte; bÃ¶ylece klinisyenlerin her bir risk faktÃ¶rÃ¼nÃ¼n aÄŸÄ±rlÄ±ÄŸÄ±nÄ± somut verilerle gÃ¶rmesine olanak tanÄ±maktadÄ±r.

![Logistic Coefficients](docs/model_evaluation/05_logistic_coefficients.png)
*Åekil 5.4.2: Logistic Regression'da en Ã¶nemli 20 Ã¶zellik (coefficient bÃ¼yÃ¼klÃ¼ÄŸÃ¼ne gÃ¶re)*

**Pozitif Coefficient (Readmission Riskini ArtÄ±rÄ±r):**

| Ã–zellik | Coefficient | Yorum |
|---------|-------------|-------|
| `number_emergency` | +0.45 | Acil baÅŸvuru geÃ§miÅŸi â†’ â†‘ Risk |
| `number_inpatient` | +0.38 | Ã–nceki yatÄ±ÅŸlar â†’ â†‘ Risk |
| `discharge_disposition_id` (bazÄ± deÄŸerler) | +0.32 | Belirli taburcu durumlarÄ± â†’ â†‘ Risk |
| `age_numeric` | +0.15 | YaÅŸ arttÄ±kÃ§a â†’ â†‘ Risk |
| `num_medications_changed` | +0.12 | Ä°laÃ§ deÄŸiÅŸikliÄŸi â†’ â†‘ Risk |

**Negatif Coefficient (Readmission Riskini AzaltÄ±r):**

| Ã–zellik | Coefficient | Yorum |
|---------|-------------|-------|
| `time_in_hospital` | -0.22 | Uzun yatÄ±ÅŸ â†’ Daha iyi tedavi â†’ â†“ Risk (belli bir noktaya kadar) |
| `num_lab_procedures` | -0.18 | Fazla test â†’ Thorough evaluation â†’ â†“ Risk |
| `has_emergency_history` | -0.08 | (Confounding etkisi olabilir) |


### 5.5 Error Analizi (Hata Analizi)

**5.5.1 SÄ±nÄ±flandÄ±rma HatalarÄ±nÄ±n Klinik ve Ekonomik Analizi**

KarÄ±ÅŸÄ±klÄ±k matrisinden (confusion matrix) elde edilen sonuÃ§lar, modelin tahmin performansÄ±nÄ±n Ã¶tesinde, saÄŸlÄ±k sistemi Ã¼zerinde doÄŸrudan klinik ve operasyonel etkilere sahiptir. Bu hata ve baÅŸarÄ± tiplerinin analiz edilmesi, modelin hastane iÅŸ akÄ±ÅŸlarÄ±na entegrasyonu iÃ§in kritik bir deÄŸerlendirme sunmaktadÄ±r:

- **DoÄŸru Tahminler (TP ve TN):** Modelin gerÃ§ek durumu baÅŸarÄ±yla Ã¶ngÃ¶rdÃ¼ÄŸÃ¼ senaryolardÄ±r. True Positive (TP) sonuÃ§larÄ±, yÃ¼ksek riskli hastalarÄ±n erken tespit edilerek kiÅŸiselleÅŸtirilmiÅŸ Ã¶nleyici bakÄ±m (preventive care) almasÄ±nÄ± saÄŸlar ve bu durum hem hasta saÄŸlÄ±ÄŸÄ± hem de hastane maliyetleri aÃ§Ä±sÄ±ndan en yÃ¼ksek deÄŸeri yaratÄ±r. True Negative (TN) durumlarÄ±nda ise dÃ¼ÅŸÃ¼k riskli hastalar normal takip sÃ¼recine dahil edilerek gereksiz kaynak kullanÄ±mÄ± Ã¶nlenmiÅŸ olur.

- **Kabul Edilebilir Sapmalar (False Positive - FP):** Modelin aslÄ±nda dÃ¼ÅŸÃ¼k riskli olan bir hasta iÃ§in "yÃ¼ksek risk" uyarÄ±sÄ± vermesidir. Klinik aÃ§Ä±dan bu durum "yÃ¶netilebilir" bir hata olarak kabul edilir; zira hastaya saÄŸlanan ilave eÄŸitim, ilaÃ§ optimizasyonu veya ekstra takip sÃ¼reÃ§lerinin hasta Ã¼zerinde herhangi bir tÄ±bbi zararÄ± bulunmamakta, aksine genel bakÄ±m kalitesini artÄ±rmaktadÄ±r.

- **Kritik Hatalar (False Negative - FN):** GerÃ§ekte yÃ¼ksek risk taÅŸÄ±yan bir hastanÄ±n model tarafÄ±ndan dÃ¼ÅŸÃ¼k riskli olarak sÄ±nÄ±flandÄ±rÄ±lmasÄ±dÄ±r. Bu durum, Ã¶nlenebilir bir tekrar yatÄ±ÅŸÄ±n gÃ¶zden kaÃ§masÄ±na, hastanÄ±n hayati komplikasyonlarla karÅŸÄ± karÅŸÄ±ya kalmasÄ±na ve saÄŸlÄ±k sistemi iÃ§in Ã§ok yÃ¼ksek tedavi maliyetlerinin oluÅŸmasÄ±na neden olduÄŸu iÃ§in klinik aÃ§Ä±dan en "kritik" hata tipi olarak tanÄ±mlanmaktadÄ±r.

**5.5.2 Model Error KarÅŸÄ±laÅŸtÄ±rmasÄ±**

| Model | TN | FP | FN | TP | FPR | FNR |
|-------|----|----|----|----|-----|-----|
| **Logistic Regression** | 11,684 | 6,399 | 983 | 1,288 | 0.354 | 0.433 |
| **Random Forest** | 15,614 | 2,469 | 1,624 | 647 | 0.137 | 0.715 |
| **XGBoost** | 17,936 | 147 | 2,169 | 102 | 0.008 | 0.955 |
| **LightGBM** | 17,863 | 220 | 2,119 | 152 | 0.012 | 0.933 |
| **SVM** | 12,513 | 5,570 | 1,162 | 1,109 | 0.308 | 0.512 |

<div style="
    border-left: 5px solid #6A1B9A;
    background-color: #E1BEE7;
    padding: 12px 14px;
    margin: 12px 0;
    border-radius: 4px;
">
<strong>ğŸ“ Ã–nemli Not</strong><br>
    
**FPR (False Positive Rate):** FP / (FP + TN) - Ne kadar false alarm?
    
**FNR (False Negative Rate):** FN / (FN + TP) - Ne kadar critical case kaÃ§Ä±rÄ±ldÄ±?
</div>

![Error Analysis](docs/model_evaluation/06_error_analysis.png)
*Åekil 5.5: Model hata tiplerinin karÅŸÄ±laÅŸtÄ±rmalÄ± analizi*

**5.5.3 Klinik Model SeÃ§imi ve Uygulama Stratejisi**

YapÄ±lan karÅŸÄ±laÅŸtÄ±rmalÄ± analizler sonucunda, klinik ortamda en verimli Ã§alÄ±ÅŸma potansiyeline sahip model olarak Lojistik Regresyon Ã¶ne Ã§Ä±kmaktadÄ±r. Bu seÃ§imin temel gerekÃ§eleri ÅŸunlardÄ±r:

- **DÃ¼ÅŸÃ¼k YanlÄ±ÅŸ Negatif OranÄ± (FNR: 0.433):** Kritik hastalarÄ± gÃ¶zden kaÃ§Ä±rma oranÄ± en dÃ¼ÅŸÃ¼k modeldir.

- **YÃ¶netilebilir YanlÄ±ÅŸ Alarm OranÄ± (FPR: 0.354):** Klinik iÅŸ akÄ±ÅŸÄ±nÄ± bozmayacak seviyede bir hatalÄ± alarm dengesi sunar.

- **YÃ¼ksek GÃ¼venilirlik ve ÅeffaflÄ±k:** Tahmin olasÄ±lÄ±klarÄ±nÄ±n kalibrasyonu yÃ¼ksektir ve katsayÄ±lar (coefficients) hekimler tarafÄ±ndan doÄŸrudan yorumlanabilir Ã¶zelliktedir.

Alternatif olarak, karar eÅŸiÄŸi (threshold) optimize edilmiÅŸ LightGBM modeli, duyarlÄ±lÄ±ÄŸÄ± (recall) artÄ±rmak adÄ±na ikinci bir seÃ§enek olarak deÄŸerlendirilmektedir; ancak bu durumun hatalÄ± alarm oranÄ±nÄ± yÃ¼kselteceÄŸi gÃ¶z Ã¶nÃ¼nde bulundurulmalÄ±dÄ±r.

### 5.6 Model Fikir BirliÄŸi (Agreement) Analizi
`Analiz KavramÄ± ve Ä°stikrar Model` fikir birliÄŸi analizi, farklÄ± algoritmalarÄ±n aynÄ± hasta Ã¶zelinde ne derece tutarlÄ± tahminler Ã¼rettiÄŸini Ã¶lÃ§mektedir. FarklÄ± matematiksel temellere sahip modellerin bir vaka Ã¼zerinde fikir birliÄŸine varmasÄ± "gÃ¼Ã§lÃ¼ sinyal" olarak kabul edilirken, fikir ayrÄ±lÄ±klarÄ± model belirsizliÄŸine ve sÄ±nÄ±r vakalara iÅŸaret etmektedir.

`KonsensÃ¼s Ä°statistikleri ve Risk GruplarÄ±` iÃ§in yapÄ±lan analiz sonucunda hastalar Ã¼Ã§ temel gÃ¼ven kategorisine ayrÄ±lmÄ±ÅŸtÄ±r:

- **YÃ¼ksek GÃ¼venli Risk Grubu (336 Ã–rnek):** Modellerin %80â€™inden fazlasÄ±nÄ±n "tekrar yatÄ±ÅŸ" Ã¶ngÃ¶rdÃ¼ÄŸÃ¼, en yÃ¼ksek riskli ve acil mÃ¼dahale gerektiren gruptur.

- **YÃ¼ksek GÃ¼venli Stabil Grup (14.892 Ã–rnek):** Modellerin bÃ¼yÃ¼k Ã§oÄŸunluÄŸunun risk gÃ¶rmediÄŸi, standart taburculuk protokollerinin yeterli olduÄŸu gruptur.

- **Belirsiz SÄ±nÄ±r Vakalar (~5.000 Ã–rnek):** AlgoritmalarÄ±n farklÄ± kararlar Ã¼rettiÄŸi, makine Ã¶ÄŸrenmesinin sÄ±nÄ±rda kaldÄ±ÄŸÄ± ve mutlaka uzman hekim gÃ¶rÃ¼ÅŸÃ¼nÃ¼n (`clinical judgment`) belirleyici olmasÄ± gereken vakalardÄ±r.

![Model Agreement](docs/model_evaluation/07_model_agreement.png)
*Åekil 5.6: Modellerin tahmin fikir birliÄŸi analizi*

## 6. HÄ°PERPARAMETRE OPTÄ°MÄ°ZASYONU

Model performansÄ±nÄ± daha da artÄ±rmak amacÄ±yla, en iyi performans gÃ¶steren tree-based modeller (Random Forest, XGBoost, LightGBM) iÃ§in hiperparametre optimizasyonu yapÄ±lmÄ±ÅŸtÄ±r. Bu bÃ¶lÃ¼mde kullanÄ±lan yÃ¶ntemler, optimal parametreler ve iyileÅŸtirme sonuÃ§larÄ± detaylandÄ±rÄ±lmÄ±ÅŸtÄ±r.

### 6.1 Hiperparametre Optimizasyon Stratejileri

**6.1.1 GridSearchCV (Sistematik Arama)**

**Ã‡alÄ±ÅŸma Prensibi:**
- Belirtilen tÃ¼m parametre kombinasyonlarÄ±nÄ± sistematik olarak dener
- Her kombinasyon iÃ§in cross-validation ile performans deÄŸerlendirmesi yapar
- Garantili olarak en iyi kombinasyonu bulur (verilen grid iÃ§inde)

**KullanÄ±m:** XGBoost iÃ§in seÃ§ildi (daha focused parameter grid ile)

**6.1.2 RandomizedSearchCV (Rastgele Arama)**

**Ã‡alÄ±ÅŸma Prensibi:**
- Parameter space'ten rastgele Ã¶rnekler seÃ§er
- Belirlenen iterasyon sayÄ±sÄ± kadar deneme yapar
- Ä°statistiksel olarak optimal sonuca yakÄ±n bulur

**KullanÄ±m:** Random Forest ve LightGBM iÃ§in seÃ§ildi

### 6.2 Optimizasyon Metrikleri

**Primary Metric: F1-Score**
- Precision ve recall'un harmonik ortalamasÄ±
- Dengesiz veri setlerinde daha anlamlÄ±
- Klinik aÃ§Ä±dan hem FP hem FN'yi dengeler

**Secondary Metric: ROC-AUC**
- Discriminative power gÃ¶stergesi
- Threshold-independent deÄŸerlendirme
- Model'in genel ayÄ±rt etme yeteneÄŸi

**Cross-Validation: 5-Fold Stratified CV** (Random Forest, LightGBM)
**Cross-Validation: 3-Fold Stratified CV** (XGBoost - hÄ±z iÃ§in)

### 6.3 Model-Specific Optimizasyon SonuÃ§larÄ±

**6.3.1 Random Forest Optimization**

**Arama Stratejisi:** RandomizedSearchCV

**Iterasyon SayÄ±sÄ±:** 50 kombinasyon Ã— 5 folds = 250 fit

**Optimizasyon SÃ¼resi:** 683.32 saniye (~11.4 dakika)

**Parameter Search Space:**
```python
{
    'n_estimators': randint(50, 300),          # 50-300 arasÄ± aÄŸaÃ§
    'max_depth': [5, 10, 15, 20, 25, None],   # AÄŸaÃ§ derinliÄŸi
    'min_samples_split': randint(2, 20),      # Split iÃ§in min Ã¶rnek
    'min_samples_leaf': randint(1, 10),       # Leaf iÃ§in min Ã¶rnek
    'max_features': ['sqrt', 'log2', None],   # Feature subsampling
    'class_weight': ['balanced', 'balanced_subsample'],
    'criterion': ['gini', 'entropy']          # Split kriteri
}
```

**En Ä°yi Hiperparametreler:**

| Parametre | Optimal DeÄŸer | AÃ§Ä±klama |
|-----------|---------------|----------|
| `n_estimators` | 207 | Ensemble'da 207 aÄŸaÃ§ |
| `max_depth` | None | Tam derinlik (no pruning) |
| `min_samples_split` | 13 | Split iÃ§in minimum 13 Ã¶rnek |
| `min_samples_leaf` | 2 | Leaf'te minimum 2 Ã¶rnek |
| `max_features` | 'sqrt' | âˆšn Ã¶zellik her split'te |
| `class_weight` | 'balanced_subsample' | Bootstrap'ta class balance |
| `criterion` | 'gini' | Gini impurity kullan |

**Performans:**
- **CV F1-Score:** 0.8587 (resampled data Ã¼zerinde)
- **Test F1-Score:** 0.1141
- **Test ROC-AUC:** 0.6589

**6.3.2 XGBoost Optimizasyon**

**Arama Stratejisi:** GridSearchCV

**Iterasyon SayÄ±sÄ±:** 6,912 kombinasyon Ã— 3 folds = 20,736 fit

**Optimizasyon SÃ¼resi:** 3566.29 saniye (~59.4 dakika)

**Parameter Grid:**
```python
{
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7, 9],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'subsample': [0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
    'gamma': [0, 0.1, 0.3],
    'min_child_weight': [1, 3, 5]
}
```

**En Ä°yi Hiperparametreler:**

| Parametre | Optimal DeÄŸer | AÃ§Ä±klama |
|-----------|---------------|----------|
| `n_estimators` | 200 | 200 boosting round |
| `max_depth` | 9 | AÄŸaÃ§ derinliÄŸi 9 |
| `learning_rate` | 0.1 | Orta hÄ±zda Ã¶ÄŸrenme |
| `subsample` | 0.9 | %90 row sampling |
| `colsample_bytree` | 0.7 | %70 feature sampling |
| `gamma` | 0.1 | Minimum loss reduction |
| `min_child_weight` | 1 | Leaf iÃ§in min weight |

**Performans:**
- **CV F1-Score:** 0.8576
- **Test F1-Score:** 0.0960
- **Test ROC-AUC:** 0.6672

**6.3.3 LightGBM Optimizasyonu**

**Arama Stratejisi:** RandomizedSearchCV

**Iterasyon SayÄ±sÄ±:** 50 kombinasyon Ã— 5 folds = 250 fit

**Optimizasyon SÃ¼resi:** 403.75 saniye (~6.7 dakika)

**Parametre DaÄŸÄ±lÄ±mÄ±:**
```python
{
    'n_estimators': randint(50, 300),
    'max_depth': randint(3, 15),
    'learning_rate': uniform(0.01, 0.3),       # Continuous
    'num_leaves': randint(20, 150),
    'subsample': uniform(0.6, 0.4),            # 0.6-1.0
    'colsample_bytree': uniform(0.6, 0.4),
    'min_child_samples': randint(10, 50),
    'reg_alpha': uniform(0, 1),                # L1 regularization
    'reg_lambda': uniform(0, 1)                # L2 regularization
}
```

**En Ä°yi Hiperparametreler:**

| Parametre | Optimal DeÄŸer | AÃ§Ä±klama |
|-----------|---------------|----------|
| `n_estimators` | 285 | 285 boosting iteration |
| `max_depth` | 14 | AÄŸaÃ§ derinliÄŸi 14 |
| `learning_rate` | 0.0650 | DÃ¼ÅŸÃ¼k learning rate |
| `num_leaves` | 108 | Leaf sayÄ±sÄ± 108 |
| `subsample` | 0.6558 | %65.6 row sampling |
| `colsample_bytree` | 0.6727 | %67.3 feature sampling |
| `min_child_samples` | 31 | Leaf iÃ§in min 31 Ã¶rnek |
| `reg_alpha` | 0.2912 | L1 regularization |
| `reg_lambda` | 0.6119 | L2 regularization |

**Performans:**
- **CV F1-Score:** 0.8584
- **Test F1-Score:** 0.1362
- **Test ROC-AUC:** 0.6809

### 6.4 Orijinal - Tuned Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

**6.4.1 Test Set Performans Tablosu**

| Model | Config | Test F1 | Test ROC-AUC | Training Time |
|-------|--------|---------|--------------|---------------|
| **Random Forest** | Original | 0.2402 | 0.6507 | 5.85s |
| **Random Forest** | Tuned | 0.1141 | 0.6589 | 683.32s |
| **XGBoost** | Original | 0.0810 | 0.6674 | 2.72s |
| **XGBoost** | Tuned | 0.0960 | 0.6672 | 3566.29s |
| **LightGBM** | Original | 0.1150 | 0.6743 | 6.47s |
| **LightGBM** | Tuned | 0.1362 | 0.6809 | 403.75s |

![Tuning Comparison](docs/hyperparameter_tuning/01_tuning_comparison.png)
*Åekil 6.4.1: Original ve tuned modellerin test performansÄ± karÅŸÄ±laÅŸtÄ±rmasÄ±*

**6.4.2 Ä°yileÅŸme Analizi**

| Model | F1-Score Ä°yileÅŸmesi | ROC-AUC Ä°yileÅŸmesi |
|-------|--------------------|--------------------|
| **Random Forest** | -52.50% âŒ | +1.25% âœ… |
| **XGBoost** | +18.64% âœ… | -0.04% â‰ˆ |
| **LightGBM** | +18.38% âœ… | +0.98% âœ… |

**Ortalama Ä°yileÅŸme:**
- **F1-Score:** -5.16% (karÄ±ÅŸÄ±k sonuÃ§)
- **ROC-AUC:** +0.73% (hafif iyileÅŸme)

![Improvement Percentage](docs/hyperparameter_tuning/02_improvement_percentage.png)
*Åekil 6.4.2: Model iyileÅŸme yÃ¼zdeleri (pozitif deÄŸerler iyileÅŸmeyi gÃ¶sterir)*


## 6.5 Hiperparametre Optimizasyonu BulgularÄ± ve Teknik DeÄŸerlendirme

**6.5.1 Beklenmedik Performans Ã‡Ä±ktÄ±larÄ± ve Analizi**

Hiperparametre optimizasyonu sÃ¼reci, her modelde doÄŸrusal bir artÄ±ÅŸ saÄŸlamamÄ±ÅŸ; Ã¶zellikle Random Forest modelinde F1 skorunda %52.5 oranÄ±nda belirgin bir dÃ¼ÅŸÃ¼ÅŸ gÃ¶zlemlenmiÅŸtir. Bu durumun temel nedeni, optimize edilen modelin SMOTE ile dengelenmiÅŸ (resampled) eÄŸitim verisine aÅŸÄ±rÄ± uyum (overfitting) saÄŸlamasÄ±dÄ±r. Ã–zellikle max_depth parametresinin sÄ±nÄ±rlandÄ±rÄ±lmamasÄ±, aÄŸaÃ§larÄ±n sentetik verideki gÃ¼rÃ¼ltÃ¼leri Ã¶ÄŸrenmesine yol aÃ§mÄ±ÅŸ ve test setindeki orijinal dengesiz daÄŸÄ±lÄ±mda genelleme yeteneÄŸini (generalization) zayÄ±flatmÄ±ÅŸtÄ±r. Buna karÅŸÄ±n, XGBoost ve LightGBM modellerinde elde edilen yaklaÅŸÄ±k %18â€™lik performans artÄ±ÅŸÄ±, boosting algoritmalarÄ±nÄ±n parametre hassasiyetine raÄŸmen veri setindeki sÄ±nÄ±f dengesizliÄŸinin hala dominant bir kÄ±sÄ±t olduÄŸunu gÃ¶stermektedir.

**6.5.2 EÄŸitim ve Test PerformansÄ± ArasÄ±ndaki Sapma (Gap)**

Ã‡alÄ±ÅŸma sonucunda, Ã§apraz doÄŸrulama (CV) skorlarÄ± ile Test skorlarÄ± arasÄ±nda yaklaÅŸÄ±k 0.72 birimlik bir F1 skoru farkÄ± tespit edilmiÅŸtir. Bu performans farkÄ± Ã¼Ã§ temel etkene dayanmaktadÄ±r:

- Veri DaÄŸÄ±lÄ±m FarklÄ±lÄ±ÄŸÄ±: Modellerin, SMOTE ile dengelenmiÅŸ eÄŸitim verisi Ã¼zerinde optimize edilmesine raÄŸmen, test setinin orijinal dengesiz yapÄ±da korunmasÄ± performansÄ±n test aÅŸamasÄ±nda dÃ¼ÅŸmesine neden olmuÅŸtur.

- Sentetik Ã–rnekleme Etkisi: Modellerin gerÃ§ek klinik vakalar yerine SMOTE tarafÄ±ndan Ã¼retilen sentetik Ã¶rÃ¼ntÃ¼lere fit olmasÄ±, gerÃ§ek dÃ¼nya verilerindeki deÄŸiÅŸkenliÄŸi tam olarak karÅŸÄ±layamamÄ±ÅŸtÄ±r.

- Metrik Hassasiyeti: F1 skoru sÄ±nÄ±f dengesizliÄŸine karÅŸÄ± oldukÃ§a hassas bir metrik olduÄŸundan, ROC-AUC skorlarÄ±ndaki sapmanÄ±n (0.91'den 0.68'e) daha dÃ¼ÅŸÃ¼k kalmasÄ± modelin ayÄ±rt etme gÃ¼cÃ¼nÃ¼n hala korunduÄŸunu kanÄ±tlamaktadÄ±r.

**6.5.3 Ã–ne Ã‡Ä±kan Hiperparametre Ã‡Ä±karÄ±mlarÄ±**

Optimizasyon sÃ¼reci, model baÅŸarÄ±sÄ±nÄ± etkileyen kritik parametreler hakkÄ±nda ÅŸu teknik iÃ§gÃ¶rÃ¼leri saÄŸlamÄ±ÅŸtÄ±r:

- Ã–ÄŸrenme OranÄ± (Learning Rate): LightGBM iÃ§in 0.065 ve XGBoost iÃ§in 0.1 deÄŸerlerinin optimal bulunmasÄ±, dÃ¼ÅŸÃ¼k Ã¶ÄŸrenme oranlarÄ±nÄ±n daha stabil bir yakÄ±nsama saÄŸladÄ±ÄŸÄ±nÄ± gÃ¶stermiÅŸtir.

- AÄŸaÃ§ DerinliÄŸi: Boosting modellerinin daha derin aÄŸaÃ§larla (9-14) daha baÅŸarÄ±lÄ± sonuÃ§lar vermesine karÅŸÄ±n, Random Forest modelinde derinliÄŸin sÄ±nÄ±rsÄ±z bÄ±rakÄ±lmasÄ± doÄŸrudan aÅŸÄ±rÄ± Ã¶ÄŸrenmeye yol aÃ§mÄ±ÅŸtÄ±r.

- DÃ¼zenlileÅŸtirme (Regularization): LightGBM modelinde kullanÄ±lan L1 ve L2 regÃ¼larizasyon teknikleri, karmaÅŸÄ±k modellerde overfitting riskini minimize eden en Ã¶nemli unsurlar olarak Ã¶ne Ã§Ä±kmÄ±ÅŸtÄ±r.

- Ã–rnekleme OranlarÄ±: %30-40 aralÄ±ÄŸÄ±nda yapÄ±lan Ã¶zellik ve Ã¶rneklem alt kÃ¼melemeleri (subsampling), modelin farklÄ± veri varyasyonlarÄ±na karÅŸÄ± direncini artÄ±rmÄ±ÅŸtÄ±r.


### 6.6 Hesaplama Maliyeti ve Performans Dengesi (Trade-off)
Model optimizasyon sÃ¼reÃ§leri, harcanan zaman ve elde edilen performans kazanÄ±mÄ± aÃ§Ä±sÄ±ndan deÄŸerlendirildiÄŸinde LightGBM, yaklaÅŸÄ±k 6.7 dakikalÄ±k optimizasyon sÃ¼resi ve test setindeki en yÃ¼ksek iyileÅŸme oranÄ±yla en verimli algoritma olarak belirlenmiÅŸtir. XGBoost modeli, 20.736 iterasyon ve yaklaÅŸÄ±k 1 saatlik iÅŸlem sÃ¼resine raÄŸmen LightGBM ile benzer bir iyileÅŸme sergilemiÅŸ; bu durum GridSearch yerine RandomSearch kullanÄ±mÄ±nÄ±n daha rasyonel olacaÄŸÄ±nÄ± kanÄ±tlamÄ±ÅŸtÄ±r. Random Forest ise harcanan hesaplama maliyetine raÄŸmen negatif bir geri dÃ¶nÃ¼ÅŸ vererek parametre seÃ§im stratejisinin yeniden gÃ¶zden geÃ§irilmesi gerektiÄŸini ortaya koymuÅŸtur.

### 6.7 Genel DeÄŸerlendirme ve Ä°yileÅŸtirme Ã–nerileri
YapÄ±lan Ã§alÄ±ÅŸma sonucunda sistematik yaklaÅŸÄ±m ve hesaplama verimliliÄŸi aÃ§Ä±sÄ±ndan Ã¶nemli baÅŸarÄ±lar elde edilse de, dengesiz veri setlerinde gerÃ§ek dÃ¼nya performansÄ±nÄ±n artÄ±rÄ±lmasÄ± iÃ§in ÅŸu stratejiler Ã¶nerilmektedir:

- GeliÅŸmiÅŸ DoÄŸrulama YÃ¶ntemleri: Gelecek Ã§alÄ±ÅŸmalarda, hiperparametre tuning iÅŸleminin gerÃ§ek veri daÄŸÄ±lÄ±mÄ±nÄ± daha iyi yansÄ±tmasÄ± iÃ§in Nested Cross-Validation yÃ¶nteminin kullanÄ±lmasÄ± tavsiye edilir.

- Maliyet OdaklÄ± YaklaÅŸÄ±m: HatalÄ± negatif (False Negative) tahminlerin klinik maliyetinin yÃ¼ksekliÄŸi gÃ¶z Ã¶nÃ¼ne alÄ±narak, optimizasyonun standart F1 skoru yerine maliyet duyarlÄ± (cost-sensitive) Ã¶zel fonksiyonlar Ã¼zerinden yapÄ±lmasÄ± performans artÄ±ÅŸÄ± saÄŸlayabilir.

- Ãœretim OrtamÄ± (Production) Stratejisi: Mevcut modeller arasÄ±nda Tuned LightGBM modelinin, karar eÅŸik deÄŸerinin (threshold) 0.25-0.30 bandÄ±na Ã§ekilmesiyle klinik takip sÃ¼reÃ§lerinde operasyonel olarak kullanÄ±labileceÄŸi deÄŸerlendirilmektedir.

## 7. MODEL YORUMLANABÄ°LÄ°RLÄ°ÄÄ°

Makine Ã¶ÄŸrenmesi modellerinin klinik ortamda kullanÄ±labilmesi iÃ§in "black-box" olmaktan Ã§Ä±karÄ±lÄ±p yorumlanabilir hale getirilmesi kritik Ã¶neme sahiptir. Bu bÃ¶lÃ¼mde SHAP (SHapley Additive exPlanations), permutation importance ve partial dependence analizi ile modellerin karar mekanizmalarÄ± aÃ§Ä±klanmÄ±ÅŸtÄ±r.

### 7.1 Klinik Ortamda YorumlanabilirliÄŸin Stratejik Ã–nemi

Makine Ã¶ÄŸrenmesi modellerinin klinik karar destek sistemlerinde yer bulabilmesi iÃ§in, bu modellerin "kapalÄ± kutu" (black-box) olmaktan Ã§Ä±karÄ±larak ÅŸeffaf ve aÃ§Ä±klanabilir hale getirilmesi temel bir gerekliliktir. SaÄŸlÄ±k profesyonellerinin bir yapay zeka modeline gÃ¼ven duyabilmesi, modelin yalnÄ±zca yÃ¼ksek doÄŸrulukla tahmin yapmasÄ±na deÄŸil, aynÄ± zamanda bu tahminlerin arkasÄ±ndaki tÄ±bbi gerekÃ§eleri sunabilmesine baÄŸlÄ±dÄ±r. Bu baÄŸlamda yorumlanabilirlik; FDA ve GDPR gibi yasal dÃ¼zenlemelerin zorunlu kÄ±ldÄ±ÄŸÄ± etik standartlarÄ±n karÅŸÄ±lanmasÄ±, modelin Ã¶ÄŸrendiÄŸi Ã¶rÃ¼ntÃ¼lerin alan uzmanlÄ±ÄŸÄ± (domain expertise) ile doÄŸrulanmasÄ± ve olasÄ± hatalÄ± tahminlerin kÃ¶k nedenlerinin analiz edilmesi aÃ§Ä±sÄ±ndan kritik bir rol oynamaktadÄ±r.

### 7.2 SHAP Analizi Metodolojisi ve UygulamasÄ±
Modellerin karar mekanizmalarÄ±nÄ± aÃ§Ä±klamak amacÄ±yla, oyun teorisinden tÃ¼retilen ve her bir Ã¶zniteliÄŸin tahmine olan marjinal katkÄ±sÄ±nÄ± hesaplayan SHAP (SHapley Additive exPlanations) yÃ¶ntemi kullanÄ±lmÄ±ÅŸtÄ±r. Ã‡alÄ±ÅŸma kapsamÄ±nda TreeExplainer ve KernelExplainer yaklaÅŸÄ±mlarÄ± aracÄ±lÄ±ÄŸÄ±yla XGBoost, LightGBM ve Random Forest modellerinin iÃ§ dinamikleri incelenmiÅŸtir. SHAP analizi, modellerin tahminleme sÃ¼recinde hangi klinik faktÃ¶rlere ne kadar aÄŸÄ±rlÄ±k verdiÄŸini yerel ve kÃ¼resel dÃ¼zeyde kesin verilerle ortaya koymaktadÄ±r.

LightGBM modeli Ã¼zerinden yapÄ±lan analizler, taburcu edilme durumunu temsil eden discharge_disposition_id deÄŸiÅŸkeninin en baskÄ±n risk faktÃ¶rÃ¼ olduÄŸunu gÃ¶stermektedir. Ã–zellikle hastalarÄ±n eve taburcu edilmek yerine Ã¶zel bakÄ±m merkezlerine veya rehabilitasyon Ã¼nitelerine sevk edilmesinin, tekrar yatÄ±ÅŸ riskini istatistiksel olarak anlamlÄ± dÃ¼zeyde artÄ±rdÄ±ÄŸÄ± saptanmÄ±ÅŸtÄ±r. Benzer ÅŸekilde, hastanÄ±n geÃ§miÅŸteki hastane yatÄ±ÅŸ sayÄ±sÄ± (number_inpatient) ve hastanede kalÄ±ÅŸ sÃ¼resince uygulanan tÄ±bbi mÃ¼dahalelerin yoÄŸunluÄŸu (procedure_intensity), hastanÄ±n genel saÄŸlÄ±k durumunun ciddiyetini yansÄ±tan gÃ¼Ã§lÃ¼ birer risk gÃ¶stergesi olarak Ã¶ne Ã§Ä±kmaktadÄ±r. Ã–nceki dÃ¶nemlerde acil servis baÅŸvuru geÃ§miÅŸi bulunan ve Ã§ok sayÄ±da tanÄ± (comorbidities) konulan hastalarÄ±n yÃ¼ksek risk grubunda yer almasÄ±, modelin klinik gerÃ§eklerle uyumlu Ã¶rÃ¼ntÃ¼ler Ã¶ÄŸrendiÄŸini doÄŸrulamaktadÄ±r.

### 7.3 Ã–zellik Ã–nem MetotlarÄ±nÄ±n KarÅŸÄ±laÅŸtÄ±rmalÄ± Analizi
Ã‡alÄ±ÅŸmada sunulan bulgularÄ±n tutarlÄ±lÄ±ÄŸÄ±nÄ± test etmek amacÄ±yla; modelin kendi iÃ§ hesaplamalarÄ± (Native Importance), SHAP deÄŸerleri ve Ã¶znitelik yer deÄŸiÅŸtirme (Permutation Importance) yÃ¶ntemleri karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r. YapÄ±lan konsensÃ¼s analizi sonucunda, number_inpatient ve discharge_disposition_id deÄŸiÅŸkenlerinin her Ã¼Ã§ yÃ¶ntemde de en yÃ¼ksek Ã¶nem derecesine sahip olduÄŸu gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r. Bu durum, sÃ¶z konusu deÄŸiÅŸkenlerin diyabetik hastalarÄ±n tekrar yatÄ±ÅŸ riskini Ã¶ngÃ¶rmede en gÃ¼venilir parametreler olduÄŸunu kanÄ±tlamaktadÄ±r. YaÅŸ ve hastanede kalÄ±ÅŸ sÃ¼resi gibi deÄŸiÅŸkenlerde ise yÃ¶ntemler arasÄ±nda gÃ¶zlemlenen farklÄ±lÄ±klar, bu Ã¶zelliklerin diÄŸer klinik verilerle olan karmaÅŸÄ±k etkileÅŸimlerine iÅŸaret etmektedir. SonuÃ§ olarak, bu Ã§ok katmanlÄ± yorumlanabilirlik analizi, modelin kararlarÄ±nÄ± rasyonel bir tÄ±bbi Ã§erÃ§eveye oturtarak klinik entegrasyon iÃ§in gerekli olan ÅŸeffaf altyapÄ±yÄ± saÄŸlamaktadÄ±r.

**LightGBM SHAP Analysis:**

**Top 10 En Ã–nemli Ã–zellikler (SHAP Importance):**


| SÄ±ra | Ã–zellik AdÄ± | Ortalama SHAP DeÄŸeri | Klinik Yorumlama ve Risk DeÄŸerlendirmesi |
| :--- | :--- | :---: | :--- |
| 1 | `discharge_disposition_id` | 0.0312 | Taburcu edilen yer (ev, rehabilitasyon merkezi vb.), tekrar yatÄ±ÅŸ riskini belirleyen en temel faktÃ¶rdÃ¼r. |
| 2 | `number_inpatient` | 0.0258 | GeÃ§miÅŸ hastane yatÄ±ÅŸ sayÄ±sÄ±, hastanÄ±n saÄŸlÄ±k hizmeti kullanÄ±m sÄ±klÄ±ÄŸÄ±nÄ± ve kronik risk dÃ¼zeyini yansÄ±tan gÃ¼Ã§lÃ¼ bir tahmin edicidir. |
| 3 | `procedure_intensity` | 0.0238 | GÃ¼nlÃ¼k prosedÃ¼r yoÄŸunluÄŸu, vaka karmaÅŸÄ±klÄ±ÄŸÄ± ve tÄ±bbi mÃ¼dahale gereksiniminin bir gÃ¶stergesidir. |
| 4 | `num_procedures` | 0.0157 | YatÄ±ÅŸ sÃ¼resince yapÄ±lan toplam prosedÃ¼r sayÄ±sÄ±, modelin karar mekanizmasÄ±nda yÃ¼ksek Ã¶neme sahiptir. |
| 5 | `has_emergency_history` | 0.0124 | YakÄ±n dÃ¶nemdeki acil servis baÅŸvuru geÃ§miÅŸi, hastalÄ±ÄŸÄ±n stabilizasyon seviyesi hakkÄ±nda kritik bilgi sunar. |
| 6 | `time_in_hospital` | 0.0086 | Hastanede kalÄ±ÅŸ sÃ¼resi, uygulanan tedavi derinliÄŸi ile tekrar yatÄ±ÅŸ olasÄ±lÄ±ÄŸÄ± arasÄ±nda doÄŸrudan bir iliÅŸki kurar. |
| 7 | `number_diagnoses` | 0.0079 | Toplam teÅŸhis sayÄ±sÄ±, hastanÄ±n komorbidite (eÅŸlik eden hastalÄ±k) yÃ¼kÃ¼nÃ¼ ve tÄ±bbi zorluÄŸunu ifade eder. |
| 8 | `age_numeric` | 0.0060 | Ä°leri yaÅŸ aralÄ±klarÄ±, fizyolojik rezervin azalmasÄ±yla baÄŸlantÄ±lÄ± olarak risk artÄ±ÅŸÄ±na neden olan bir unsurdur. |
| 9 | `insulin` | 0.0060 | Ä°nsÃ¼lin kullanÄ±mÄ± ve dozaj stabilitesi, diyabet yÃ¶netimindeki kontrol ve ÅŸiddet seviyesini simgeler. |
| 10 | `diag_1_freq` | 0.0050 | Birincil teÅŸhisÃ¼n gÃ¶rÃ¼lme sÄ±klÄ±ÄŸÄ±, belirli hastalÄ±k tÃ¼rlerinin risk Ã¼zerindeki istatistiksel aÄŸÄ±rlÄ±ÄŸÄ±nÄ± Ã¶lÃ§er. |


**SHAP Effects Yorumlama:**

Modelin karar mekanizmasÄ± Ã¼zerindeki Ã¶znitelik etkileri incelendiÄŸinde, taburcu edilme durumu (`Discharge Disposition`) en belirgin belirleyicilerden biri olarak Ã¶ne Ã§Ä±kmaktadÄ±r; yÃ¼ksek ID deÄŸerine sahip Ã¶zel bakÄ±m merkezlerine sevk edilen hastalarÄ±n pozitif SHAP deÄŸerleri sergileyerek daha yÃ¼ksek risk taÅŸÄ±dÄ±ÄŸÄ±, eve taburcu edilenlerin ise daha dÃ¼ÅŸÃ¼k risk grubunda yer aldÄ±ÄŸÄ± saptanmÄ±ÅŸtÄ±r. GeÃ§miÅŸ yatarak tedavi sayÄ±larÄ± (`Number Inpatient`) analiz edildiÄŸinde, ikiden fazla yatÄ±ÅŸ geÃ§miÅŸi olan hastalarÄ±n riskinin belirgin ÅŸekilde arttÄ±ÄŸÄ± gÃ¶rÃ¼lmekte olup bu durum saÄŸlÄ±k hizmeti kullanÄ±m geÃ§miÅŸinin gÃ¼Ã§lÃ¼ bir tahmin edici olduÄŸunu kanÄ±tlamaktadÄ±r. AyrÄ±ca, prosedÃ¼r yoÄŸunluÄŸundaki (`Procedure Intensity`) artÄ±ÅŸÄ±n pozitif SHAP deÄŸerleriyle risk artÄ±ÅŸÄ±na yol aÃ§masÄ±, yoÄŸun tÄ±bbi mÃ¼dahale gereksiniminin vaka karmaÅŸÄ±klÄ±ÄŸÄ± ve tekrar yatÄ±ÅŸ olasÄ±lÄ±ÄŸÄ± iÃ§in kritik bir klinik iÅŸaret olduÄŸunu ortaya koymaktadÄ±r.

### 7.3 Ã–znitelik Ã–nem DÃ¼zeylerinin KarÅŸÄ±laÅŸtÄ±rmalÄ± Analizi

ÃœÃ§ farklÄ± importance metodu karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r:
Ã‡alÄ±ÅŸma kapsamÄ±nda modellerin karar verme sÃ¼reÃ§lerini anlamlandÄ±rmak amacÄ±yla Ã¼Ã§ farklÄ± Ã¶nem belirleme metodolojisi karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r. Ä°lk olarak kullanÄ±lan Modele Ã–zgÃ¼ Ã–nem (`Native Importance`) yÃ¶ntemi; Random Forest iÃ§in Gini saflÄ±ÄŸÄ±, XGBoost ve LightGBM iÃ§in ise kazanÃ§ tabanlÄ± hesaplamalara dayanmaktadÄ±r. Bu yÃ¶ntemin en bÃ¼yÃ¼k avantajÄ± hesaplama hÄ±zÄ±nÄ±n yÃ¼ksek olmasÄ±dÄ±r; ancak yÃ¼ksek kardinaliteye sahip deÄŸiÅŸkenlere karÅŸÄ± yanlÄ±lÄ±k gÃ¶sterme riski bir dezavantaj olarak deÄŸerlendirilmektedir. Ä°kinci olarak uygulanan SHAP Ã–nem Analizi, her bir Ã¶zelliÄŸin ortalama mutlak Shapley deÄŸerlerini temel alarak teorik aÃ§Ä±dan Ã§ok daha saÄŸlam ve tarafsÄ±z bir deÄŸerlendirme sunmaktadÄ±r. SHAP yÃ¶ntemi Ã¶znitelik etkilerini en doÄŸru ÅŸekilde yansÄ±tsa da, yÃ¼ksek hesaplama maliyeti operasyonel bir kÄ±sÄ±t oluÅŸturmaktadÄ±r.

Son olarak kullanÄ±lan PermÃ¼tasyon Ã–nemi (`Permutation Importance`) yÃ¶ntemi ise, belirli bir Ã¶zelliÄŸin deÄŸerleri rastgele karÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda (`shuffle`) model performansÄ±nda meydana gelen dÃ¼ÅŸÃ¼ÅŸÃ¼ Ã¶lÃ§erek Ã¶zniteliÄŸin gerÃ§ek etkisini saptamaktadÄ±r. Modelden baÄŸÄ±msÄ±z Ã§alÄ±ÅŸabilmesi ve gerÃ§ek dÃ¼nya etkisini doÄŸrudan Ã¶lÃ§ebilmesi bu yÃ¶ntemin gÃ¼Ã§lÃ¼ yÃ¶nÃ¼yken; birbiriyle yÃ¼ksek korelasyona sahip Ã¶zellikler bulunduÄŸunda sonuÃ§larÄ±n gÃ¼venilirliÄŸinin azalmasÄ± temel limitasyonu olarak gÃ¶rÃ¼lmektedir. Bu Ã¼Ã§ yÃ¶ntemin birlikte kullanÄ±lmasÄ±, klinik deÄŸiÅŸkenlerin tahmin gÃ¼cÃ¼ Ã¼zerinde Ã§ok boyutlu ve doÄŸrulanmÄ±ÅŸ bir bakÄ±ÅŸ aÃ§Ä±sÄ± elde edilmesini saÄŸlamÄ±ÅŸtÄ±r.

Top 10 Ã¶zelliklerin 3 metottaki sÄ±ralamasÄ±:

| Ã–zellik | Modele Ã–zgÃ¼ | SHAP DeÄŸeri | PermÃ¼tasyon | Fikir BirliÄŸi |
|---------|--------|------|-------------|-----------|
| `number_inpatient` | 1 | 2 | 1 | âœ… GÃ¼Ã§lÃ¼ |
| `discharge_disposition_id` | 4 | 1 | 4 | âœ… GÃ¼Ã§lÃ¼ |
| `age_numeric` | 2 | 8 | 13 | âš ï¸ Karma |
| `time_in_hospital` | 3 | 6 | 23 | âŒ ZayÄ±f |
| `procedure_intensity` | 11 | 3 | 30 | âš ï¸ Karma |


## 8. SONUÃ‡ VE TARTIÅMA

Bu proje, diabetik hastalarÄ±n 30 gÃ¼n iÃ§inde hastaneye tekrar yatÄ±ÅŸ riskini tahmin etmek iÃ§in kapsamlÄ± bir makine Ã¶ÄŸrenmesi Ã§alÄ±ÅŸmasÄ± gerÃ§ekleÅŸtirmiÅŸtir. Veri keÅŸfinden model deployment Ã¶nerisine kadar tÃ¼m data science pipeline uygulanmÄ±ÅŸ ve detaylÄ± dokÃ¼mante edilmiÅŸtir.

### 8.1 Proje AmaÃ§larÄ±nÄ±n DeÄŸerlendirilmesi

| # | AmaÃ§ | BaÅŸarÄ± Durumu | AÃ§Ä±klama |
|---|------|---------------|----------|
| 1 | KapsamlÄ± veri analizi | âœ… TamamlandÄ± | 101,766 hasta, 50 Ã¶zellik detaylÄ± analiz edildi |
| 2 | Veri Ã¶n iÅŸleme ve feature engineering | âœ… TamamlandÄ± | 8 yeni Ã¶zellik, encoding, scaling uygulandÄ± |
| 3 | 3+ farklÄ± ML modeli eÄŸitimi | âœ… TamamlandÄ± | 5 model eÄŸitildi (LR, RF, XGB, LGBM, SVM) |
| 4 | Model performans deÄŸerlendirme | âœ… TamamlandÄ± | Comprehensive metrics, ROC, PR curves |
| 5 | Hiperparametre optimizasyonu | âœ… TamamlandÄ± | GridSearch ve RandomSearch uygulandÄ± |
| 6 | Model yorumlanabilirliÄŸi | âœ… TamamlandÄ± | SHAP, feature importance, PDP analizi |

**SonuÃ§:** TÃ¼m proje amaÃ§larÄ± baÅŸarÄ±yla tamamlanmÄ±ÅŸtÄ±r. âœ…

### 8.2 Temel Bulgular ve SonuÃ§lar

**En Ä°yi Modeller (Test Set):**

| Metrik | En Ä°yi Model | DeÄŸer | Yorum |
|--------|--------------|-------|-------|
| **Recall (En Kritik)** | Logistic Regression | 0.567 | En az kritik hasta kaÃ§Ä±rÄ±yor |
| **F1-Score** | Logistic Regression | 0.259 | Dengeli performans |
| **ROC-AUC** | LightGBM | 0.674 | En iyi discrimination power |
| **Precision** | XGBoost | 0.410 | En az false alarm |
| **Kalibrasyon** | Logistic Regression | MÃ¼kemmel | GÃ¼venilir probabilities |

Modellerin karÅŸÄ±laÅŸtÄ±rmalÄ± analizi sonucunda, Lojistik Regresyon en yÃ¼ksek duyarlÄ±lÄ±k (0.567 recall) oranÄ±nÄ± sunarak kritik hastalarÄ± tespit etme konusunda en baÅŸarÄ±lÄ± model olarak Ã¶ne Ã§Ä±kmÄ±ÅŸ; yorumlanabilir katsayÄ±larÄ± ve yÃ¼ksek kalibrasyon kalitesiyle klinik kullanÄ±ma en uygun seÃ§enek olarak deÄŸerlendirilmiÅŸtir. Buna karÅŸÄ±n, LightGBM hiperparametre optimizasyonu ile F1 skorunda %18â€™lik bir artÄ±ÅŸ yakalayarak en yÃ¼ksek ROC-AUC (0.681) deÄŸerine ulaÅŸsa da, zayÄ±f kalibrasyonu ve dÃ¼ÅŸÃ¼k duyarlÄ±lÄ±k oranÄ± nedeniyle operasyonel kÄ±sÄ±tlar sergilemektedir. XGBoost ve Random Forest yÃ¼ksek doÄŸruluk oranlarÄ±na raÄŸmen kritik hastalarÄ±n %95'inden fazlasÄ±nÄ± kaÃ§Ä±rÄ±rken, SVM modeli hesaplama maliyetinin yÃ¼ksekliÄŸi nedeniyle pratik uygulamalar iÃ§in verimli bulunmamÄ±ÅŸtÄ±r.

SÄ±nÄ±f dengesizliÄŸiyle mÃ¼cadele kapsamÄ±nda uygulanan SMOTE ve rastgele alt Ã¶rnekleme yÃ¶ntemleri, Ã§apraz doÄŸrulama performansÄ±nÄ± kaÄŸÄ±t Ã¼zerinde artÄ±rsa da, test setinde beklenen iyileÅŸmeyi saÄŸlamamÄ±ÅŸ ve sentetik Ã¶rneklerin gerÃ§ek dÃ¼nya verileri Ã¼zerindeki tahmin performansÄ±nÄ± yanÄ±ltabileceÄŸini (misleading) ortaya koymuÅŸtur. Hiperparametre optimizasyonu tarafÄ±nda LightGBM ve XGBoost modelleri performanslarÄ±nÄ± %18 civarÄ±nda artÄ±rÄ±rken, Random Forest modeli aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting) nedeniyle ciddi bir performans kaybÄ± yaÅŸamÄ±ÅŸtÄ±r. Hesaplama maliyeti aÃ§Ä±sÄ±ndan LightGBM 6.7 dakikalÄ±k sÃ¼resiyle en verimli model olurken, XGBoost 59 dakikalÄ±k sÃ¼resiyle en maliyetli yÃ¶ntem olmuÅŸtur. Gelecekteki iyileÅŸtirmeler iÃ§in maliyet-duyarlÄ± Ã¶ÄŸrenme (cost-sensitive learning) ve karar eÅŸiÄŸi optimizasyonu gibi daha agresif stratejilerin kullanÄ±lmasÄ± Ã¶nerilmektedir.

### 8.3 Klinik ve Pratik Ã‡Ä±karÄ±mlar ve Uygulama Ã–nerileri

YapÄ±lan analizler sonucunda, diyabetik hastalarÄ±n tekrar yatÄ±ÅŸ riskini belirleyen en gÃ¼Ã§lÃ¼ klinik gÃ¶stergelerin hastane kullanÄ±m geÃ§miÅŸi (acil servis ve yatarak tedavi sayÄ±larÄ±) ile taburcu edildikleri merkez tÃ¼rÃ¼ olduÄŸu saptanmÄ±ÅŸtÄ±r. Ã–zellikle 70 yaÅŸ Ã¼zeri popÃ¼lasyon, yÃ¼ksek prosedÃ¼r yoÄŸunluÄŸu ve Ã§oklu tanÄ±ya (komorbidite) sahip hastalar en riskli grubu oluÅŸturmaktadÄ±r; bu durum, klinik sÃ¼reÃ§lerde yaÅŸa Ã¶zel protokollerin ve koordineli bakÄ±m programlarÄ±nÄ±n Ã¶nemini ortaya koymaktadÄ±r. Model deÄŸerlendirme aÅŸamasÄ±nda, %57â€™lik duyarlÄ±lÄ±k (recall) oranÄ±, yÃ¼ksek kalibrasyon baÅŸarÄ±sÄ± ve ÅŸeffaf yorumlanabilirlik Ã¶zellikleri nedeniyle Lojistik Regresyon modelinin (eÅŸik deÄŸeri 0.35-0.40) klinik kullanÄ±m iÃ§in en uygun Ã§Ã¶zÃ¼m olduÄŸu belirlenmiÅŸtir. Bu modelin karar destek sistemlerine entegre edilmesi, yÃ¼ksek riskli hastalarÄ±n taburculuk Ã¶ncesinde gerÃ§ek zamanlÄ± olarak tespit edilmesine ve kiÅŸiselleÅŸtirilmiÅŸ mÃ¼dahale planlarÄ±yla tekrar yatÄ±ÅŸ oranlarÄ±nÄ±n minimize edilmesine olanak saÄŸlayacaktÄ±r.

**GeliÅŸtirme SÃ¼reci:**

```
1. HastanÄ±n Taburculuk SÃ¼recinin BaÅŸlatÄ±lmasÄ±
   â†“
2. Klinik Verilerin ve Ã–zniteliklerin (Features) ToplanmasÄ±
   â†“
3. Tekrar YatÄ±ÅŸ OlasÄ±lÄ±ÄŸÄ±nÄ±n (Readmission Probability) HesaplanmasÄ±
   â†“
4. Risk TabakalandÄ±rma (Risk Stratification):
   - P > 0.40: YÃœKSEK RÄ°SK â†’ YoÄŸun Takip ve MÃ¼dahale ProgramÄ±
   - 0.20 < P < 0.40: ORTA RÄ°SK â†’ Standart Ä°zlem ve Taburculuk SonrasÄ± Kontrol
   - P < 0.20: DÃœÅÃœK RÄ°SK â†’ Rutin BakÄ±m ve Standart Protokol
   â†“
5. Risk FaktÃ¶rlerinin GÃ¶rselleÅŸtirilmesi (SHAP AÃ§Ä±klamalarÄ±)
   â†“
6. Klinik Uzman DeÄŸerlendirmesi ve Nihai Karar
```

**Beklenen Ã‡Ä±ktÄ±lar:**

GeliÅŸtirilen modelin beklenen Ã§Ä±ktÄ±larÄ± ÅŸu ÅŸekilde Ã¶zetlenebilir: Model, yaklaÅŸÄ±k %57'lik duyarlÄ±lÄ±k (recall) oranÄ±yla kritik durumdaki hastalarÄ±n yarÄ±dan fazlasÄ±nÄ± Ã¶nceden tespit edebilme kapasitesine sahiptir. %65'lik Ã¶zgÃ¼llÃ¼k (specificity) oranÄ± sayesinde dÃ¼ÅŸÃ¼k riskli hastalar baÅŸarÄ±yla ayÄ±rt edilirken, %35 seviyesindeki hatalÄ± alarm oranÄ± klinik aÃ§Ä±dan kabul edilebilir bir eÅŸik olarak deÄŸerlendirilmektedir; zira dÃ¼ÅŸÃ¼k riskli bir hastaya saÄŸlanan ilave Ã¶nleyici bakÄ±mÄ±n herhangi bir tÄ±bbi zararÄ± bulunmamaktadÄ±r.

**8.3.3 Operasyonel Faydalar**

GeliÅŸtirilen tahmin modelinin saÄŸlÄ±k sistemi Ã¼zerindeki operasyonel yansÄ±malarÄ±; maliyet yÃ¶netimi, hizmet kalitesi ve bakÄ±m koordinasyonu olmak Ã¼zere Ã¼Ã§ temel eksende stratejik avantajlar sunmaktadÄ±r. Modelin 30 gÃ¼nlÃ¼k tekrar yatÄ±ÅŸlarÄ± Ã¶nleme kabiliyeti, hastanelerin Medicare cezalarÄ±ndan kaÃ§Ä±nmasÄ±nÄ± saÄŸlamanÄ±n yanÄ± sÄ±ra kaynak optimizasyonu yoluyla ciddi bir maliyet tasarrufu potansiyeli yaratmaktadÄ±r. Hizmet kalitesi aÃ§Ä±sÄ±ndan ise daha etkin taburculuk planlamasÄ± ve hedefli klinik mÃ¼dahaleler, hasta memnuniyetinde doÄŸrudan bir artÄ±ÅŸ saÄŸlamaktadÄ±r. BakÄ±m koordinasyonu sÃ¼recinde yÃ¼ksek riskli hastalarÄ±n erken tespiti, taburcu sonrasÄ± kiÅŸiselleÅŸtirilmiÅŸ takip programlarÄ±nÄ±n ve multidisipliner bakÄ±m ekiplerinin devreye alÄ±nmasÄ±na olanak tanÄ±yarak sistemin operasyonel verimliliÄŸini artÄ±rmaktadÄ±r. Ekonomik aÃ§Ä±dan somut bir projeksiyon yapÄ±ldÄ±ÄŸÄ±nda; hasta baÅŸÄ±na yaklaÅŸÄ±k 15.000 dolarlÄ±k tekrar yatÄ±ÅŸ maliyeti Ã¼zerinden, modelin yÄ±llÄ±k 1.000 yÃ¼ksek riskli hastada yatÄ±ÅŸlarÄ± sadece %10 oranÄ±nda Ã¶nlemesi bile kurum iÃ§in yÄ±llÄ±k yaklaÅŸÄ±k 1,5 milyon dolarlÄ±k bir yatÄ±rÄ±m getirisi (ROI) ve doÄŸrudan tasarruf anlamÄ±na gelmektedir.

### 8.4 Projenin GÃ¼Ã§lÃ¼ YÃ¶nleri

Bu Ã§alÄ±ÅŸma, diyabetik hastalarÄ±n hastaneye tekrar yatÄ±ÅŸ risklerini tahmin etme sÃ¼recinde uÃ§tan uca kurgulanmÄ±ÅŸ kapsamlÄ± bir veri bilimi boru hattÄ± (pipeline) sunmasÄ± bakÄ±mÄ±ndan oldukÃ§a gÃ¼Ã§lÃ¼ bir yapÄ±ya sahiptir. 130 hastaneden toplanan ve 10 yÄ±llÄ±k bir sÃ¼reci kapsayan 101.000'den fazla gerÃ§ek dÃ¼nya verisiyle Ã§alÄ±ÅŸÄ±lmÄ±ÅŸ olmasÄ±, elde edilen sonuÃ§larÄ±n istatistiksel gÃ¼venilirliÄŸini artÄ±rmaktadÄ±r. Metodolojik olarak sadece tek bir algoritma ile yetinilmemiÅŸ; Lojistik Regresyonâ€™dan modern topluluk Ã¶ÄŸrenme (ensemble) yÃ¶ntemlerine kadar 5 farklÄ± algoritma titizlikle karÅŸÄ±laÅŸtÄ±rÄ±larak en uygun Ã§Ã¶zÃ¼m aranmÄ±ÅŸtÄ±r. Projenin teknik derinliÄŸi ise yalnÄ±zca model eÄŸitimiyle sÄ±nÄ±rlÄ± kalmayÄ±p; SHAP analizi ile model kararlarÄ±nÄ±n yorumlanabilir kÄ±lÄ±nmasÄ±, eÅŸik deÄŸeri (threshold) optimizasyonu ve model kalibrasyonu gibi ileri seviye tekniklerin baÅŸarÄ±yla uygulanmasÄ±yla pekiÅŸtirilmiÅŸtir. AyrÄ±ca, klinik alan bilgisinin Ã¶zellik mÃ¼hendisliÄŸi sÃ¼reÃ§lerine entegre edilmesi ve projenin her aÅŸamasÄ±nÄ±n tekrarlanabilirliÄŸi (reproducibility) saÄŸlayacak ÅŸekilde detaylÄ±ca dokÃ¼mante edilmesi, projenin hem akademik hem de pratik deÄŸerini en Ã¼st seviyeye taÅŸÄ±maktadÄ±r.

### 8.5 Projenin ZayÄ±f YÃ¶nleri ve Limitasyonlar

Bu Ã§alÄ±ÅŸma, diyabetik hastalarÄ±n tekrar yatÄ±ÅŸ risklerinin tahmininde Ã¶nemli Ã§Ä±ktÄ±lar sunsa da, sonuÃ§larÄ±n yorumlanmasÄ± aÅŸamasÄ±nda dikkate alÄ±nmasÄ± gereken birtakÄ±m veri ve model kaynaklÄ± kÄ±sÄ±tlar bulunmaktadÄ±r. Veri seti dÃ¼zeyindeki en belirgin kÄ±sÄ±t, analize dahil edilen kayÄ±tlarÄ±n 1999-2008 yÄ±llarÄ±nÄ± kapsamasÄ±dÄ±r; bu durum, son on beÅŸ yÄ±lda deÄŸiÅŸen saÄŸlÄ±k hizmeti uygulamalarÄ±nÄ±n ve modern tedavi protokollerinin modele tam olarak yansÄ±tÄ±lamamasÄ±na neden olmaktadÄ±r. AyrÄ±ca, veri setinde kilo (%96+) ve tÄ±bbi uzmanlÄ±k alanÄ± (%49+) gibi kritik deÄŸiÅŸkenlerdeki yÃ¼ksek eksiklik oranlarÄ± potansiyel bilgi kaybÄ±na yol aÃ§mÄ±ÅŸ; laboratuvar sonuÃ§larÄ±nÄ±n sayÄ±sal deÄŸerleri, yaÅŸamsal bulgular ve saÄŸlÄ±ÄŸÄ±n sosyal belirleyicileri gibi parametrelerin eksikliÄŸi ise modelin bÃ¼tÃ¼ncÃ¼l (holistic) bir risk deÄŸerlendirmesi yapma kabiliyetini sÄ±nÄ±rlamÄ±ÅŸtÄ±r.

Modelleme performansÄ± aÃ§Ä±sÄ±ndan bakÄ±ldÄ±ÄŸÄ±nda, test setinde elde edilen 0.65-0.68 aralÄ±ÄŸÄ±ndaki ROC-AUC deÄŸerleri, modellerin ayÄ±rt edici gÃ¼cÃ¼nÃ¼n orta seviyede olduÄŸunu gÃ¶stermektedir. Veri setindeki %11,16â€™lÄ±k azÄ±nlÄ±k sÄ±nÄ±f oranÄ± nedeniyle yaÅŸanan belirgin sÄ±nÄ±f dengesizliÄŸi, "Recall" ve "Precision" metrikleri arasÄ±nda zorunlu bir Ã¶dÃ¼nleÅŸime (trade-off) yol aÃ§mÄ±ÅŸtÄ±r. Ã–zellikle Ã§apraz doÄŸrulama aÅŸamasÄ±ndaki yÃ¼ksek F1 skorlarÄ± ile test setindeki dÃ¼ÅŸÃ¼k sonuÃ§lar arasÄ±ndaki fark, modellerin sentetik veriye aÅŸÄ±rÄ± uyum saÄŸladÄ±ÄŸÄ±nÄ± ve Ã¼retim ortamÄ±ndaki performansÄ±n laboratuvar sonuÃ§larÄ±ndan daha dÃ¼ÅŸÃ¼k olabileceÄŸini kanÄ±tlamaktadÄ±r.

Son olarak, projenin genellenebilirliÄŸi ve uygulama sÃ¼reci Ã¶nÃ¼nde genel limitasyonlar mevcuttur. Verilerin yalnÄ±zca ABD hastanelerinden toplanmÄ±ÅŸ olmasÄ±, farklÄ± saÄŸlÄ±k sistemleri iÃ§in modelin dÄ±ÅŸsal geÃ§erliliÄŸini (external validity) belirsiz kÄ±lmaktadÄ±r. On yÄ±llÄ±k tarihsel bir kesite dayanÄ±lmasÄ± ve ileriye dÃ¶nÃ¼k (prospective) bir validasyonun henÃ¼z yapÄ±lmamÄ±ÅŸ olmasÄ±, modelin gelecekteki performansÄ±na dair belirsizlikler yaratmaktadÄ±r. AyrÄ±ca, modelin klinik ortamlarda hayata geÃ§irilmesi iÃ§in gerekli olan elektronik saÄŸlÄ±k kayÄ±tlarÄ± (EHR) entegrasyonu ve saÄŸlÄ±k personeli eÄŸitimleri gibi operasyonel gereklilikler, adaptasyon sÃ¼recinde karÅŸÄ±laÅŸÄ±labilecek temel engeller olarak deÄŸerlendirilmektedir.

### 8.6 Gelecek Ã‡alÄ±ÅŸmalar iÃ§in Ã–neriler

Bu Ã§alÄ±ÅŸma ile elde edilen bulgular, diyabetik hastalarÄ±n tekrar yatÄ±ÅŸ risklerinin tahmininde Ã¶nemli bir temel oluÅŸturmakla birlikte, modelin baÅŸarÄ±sÄ±nÄ± ve klinik yararlÄ±lÄ±ÄŸÄ±nÄ± artÄ±rmak adÄ±na gelecekte atÄ±labilecek stratejik adÄ±mlar bulunmaktadÄ±r. Veri kalitesini iyileÅŸtirmek amacÄ±yla, 2020 yÄ±lÄ± ve sonrasÄ±na ait gÃ¼ncel tÄ±bbi verilerin toplanarak modern saÄŸlÄ±k uygulamalarÄ±nÄ±n modele yansÄ±tÄ±lmasÄ± ilk Ã¶ncelik olmalÄ±dÄ±r. Buna ek olarak, laboratuvar sonuÃ§larÄ± (HbA1c, glukoz seviyeleri), hayati bulgular ve sosyal belirleyiciler gibi daha kapsamlÄ± Ã¶zniteliklerin dahil edilmesi, hastalarÄ±n klinik tablosunun daha bÃ¼tÃ¼ncÃ¼l bir ÅŸekilde analiz edilmesine imkÃ¢n tanÄ±yacaktÄ±r. Teknik aÃ§Ä±dan ise derin Ã¶ÄŸrenme mimarilerinin (LSTM, Transformers) kullanÄ±lmasÄ±, saÄŸkalÄ±m analizi yaklaÅŸÄ±mlarÄ± ve hatalÄ± negatif tahminlerin maliyetini minimize eden "maliyet-duyarlÄ± Ã¶ÄŸrenme" (cost-sensitive learning) yÃ¶ntemleri, tahmin hassasiyetini Ã¼st seviyeye taÅŸÄ±yabilecek potansiyel geliÅŸtirme alanlarÄ±dÄ±r.

GeliÅŸtirilen modellerin pratik hayattaki etkinliÄŸini doÄŸrulamak iÃ§in gerÃ§ek zamanlÄ± pilot uygulamalar (prospective studies) ve farklÄ± hastaneleri kapsayan Ã§ok merkezli validasyon Ã§alÄ±ÅŸmalarÄ±nÄ±n yÃ¼rÃ¼tÃ¼lmesi bÃ¼yÃ¼k Ã¶nem arz etmektedir. Modelin klinik karar destek sistemlerine (CDSS) entegre edilmesi sÃ¼recinde, FHIR standartlarÄ± kullanÄ±larak elektronik saÄŸlÄ±k kayÄ±tlarÄ± (EHR) ile tam uyumlu ve otomatik skorlama yapabilen bir yapÄ± kurgulanmalÄ±dÄ±r. Son olarak, model performansÄ±nÄ±n zaman iÃ§indeki deÄŸiÅŸimini (data drift) takip eden sÃ¼rekli izleme mekanizmalarÄ±nÄ±n kurulmasÄ± ve dÃ¶nemsel yeniden eÄŸitim (retraining) sÃ¼reÃ§lerinin iÅŸletilmesi, sistemin uzun vadeli gÃ¼venilirliÄŸini ve sÃ¼rdÃ¼rÃ¼lebilirliÄŸini garanti altÄ±na alacaktÄ±r.


```python

```
